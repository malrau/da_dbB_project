{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b658c051",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h2>Online learning platform database - Redis</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544d0b6",
   "metadata": {},
   "source": [
    "<h3>Preliminary operations: import csv files into Redis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf09d3",
   "metadata": {},
   "source": [
    "Given Redis' nature of a <i>key-value store</i> rather than a DBMS in a classical form, importing is a task better performed via a programming language API. This requires to load the csv file and store the data into a suitable data structure, then use the programming language API to connect to a Redis instance and store the data into a Redis data type. Hence, this section on Redis will have a slightly different format from the previous ones, it will start directly with introducing the Python driver for Redis and ways to connect to a Redis instance from Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5e089",
   "metadata": {},
   "source": [
    "<h3>Importing csv files into Python</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b855d73",
   "metadata": {},
   "source": [
    "Importing a csv file into Python is best performed via the <code>csv</code> module, contained in the Python standard library. It contains methods to read <code>csv.reader</code> or write <code>csv.writer</code> csv files. By starting a connection to a file we can read it line by line and store the fields within each line into lists. The file lines can be stored into a dictionary of lists where each line number corresponds to the dictionary key and the associated list contains the fields included in the csv lines. The above described procedure is stored into a function that can be called for each of the four datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: stores a csv file into a Python dictionary (dictionary keys are row numbers, values are rows as lists)\n",
    "# arguments: a path (string), a csv filename including extension (string), a dictionary name\n",
    "# RETURNS: a dictionary\n",
    "def importCSVfile(pathName, csvFileName, dictName):\n",
    "    import csv\n",
    "    key = 0\n",
    "    dictName = dict()\n",
    "    with open(pathName + csvFileName, newline = '') as csvFile:\n",
    "        reader = csv.reader(csvFile, delimiter = ',')\n",
    "        for line in reader:\n",
    "            dictName[key] = line\n",
    "            key += 1\n",
    "    return dictName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a75ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the importCSVfile function for the four differently sized datasets\n",
    "path = '/Users/mau/OneDrive - unime.it/Learning/CdL Informatica/Anno II - Database/Module B/project/tables/'\n",
    "\n",
    "# 250k rows dataset to dict\n",
    "importCSVfile(path, 'dataset250k.csv', smallDB)\n",
    "\n",
    "# 500k rows dataset to dict\n",
    "importCSVfile(path, 'dataset500k.csv', mediumDB)\n",
    "\n",
    "# 750k rows dataset to dict\n",
    "importCSVfile(path, 'dataset750k.csv', largeDB)\n",
    "\n",
    "# 1m rows dataset to dict\n",
    "importCSVfile(path, 'dataset1m.csv', humongousDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2097dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of the four dictionaries, from the smallest to the largest:\n",
      "250001 500001 750001 1000001\n"
     ]
    }
   ],
   "source": [
    "print('Lengths of the four dictionaries, from the smallest to the largest:\\n')\n",
    "print('smallDB:', len(datasetSmall), 'mediumDB:', len(datasetMedium), 'largeDB:', len(datasetLarge), 'humongousDB:', len(datasetHumongous))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe4135",
   "metadata": {},
   "source": [
    "<h3>Python - Redis interaction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad76a4",
   "metadata": {},
   "source": [
    "Interaction between a Python API and a Redis key-value store requires the installation of a specific driver. The usual list of drivers for various programming languages is provided in the <a href = 'https://redis.io/resources/clients/'>Clients</a> web page of the Redis website: <a href = 'https://redis-py.readthedocs.io/en/stable/index.html'>redis-py</a> is the driver developed by <i>Redis Inc.</i> for a Python programming environment.<br>After having installed the driver, it can be imported into a Python environment the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5469de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddef33",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Establishing a connection to a Redis database\n",
    "</h4><br>\n",
    "We can connect to a Redis instance by simply assigning a <code>Redis()</code> object to a Python variable. By default, the driver sets a connection to a local Redis instance on port 6379. Host name and port can also be specified as arguments. By default, Redis returns responses as bytes in Python. We can be returned responses decoded as strings by specifying the <code>decode_responses</code> argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629d30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRedis = redis.Redis(host = 'localhost', port = 6379, decode_responses = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccffa2dd",
   "metadata": {},
   "source": [
    "A Redis connection implements a <code>CoreCommands</code> class which contains functions that can replicate all the <a href = 'https://redis-py.readthedocs.io/en/stable/commands.html'>commands</a> provided within the <i>redis-cli</i> API. Since Python is case sensitive, however, they must be typed in the correct letter case (they usually use lowercase letters). The list of all available methods is accessible via the usual <code>dir(<i>redisObject</i>)</code> function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0ab66",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Store data into Redis hashes [ ! LONG PROCESSES FOLLOW ! ]\n",
    "</h4><br>\n",
    "<i>Hashes</i> are a Redis data type that allows the association of keys and values. A hash object has a name and a list of key-value stores. In our case, the keys may represent the field (column) names contained in the first row of the csv file (header) while the values are the field values contained in the other csv rows. We can create one hash per row by creating hash names of the form <i>small:rownumber</i>, where the text before the colon represents the dataset and the text after the colon is the row number. Thus, each row becomes a hash where the hash keys are common across all hashes in the dataset. This is helpful because hash keys may work as a schema for implementing queries. This procedure is stored into a function that takes a dictionary as argument, so that it is sufficient to feed it the desired dataset (one of the four differently sized dataset stored into the four dictionaries above) to have data sent to Redis (the process is quite long even for the 250k rows dataset, anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0688a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: stores Python dictionary key-value pairs to Redis hashes with a prefix\n",
    "# arguments: a Redis instance, a dictionary(dict), a string we want to use as hash prefix\n",
    "# (usually the hash string ends with a colon to separate prefix and row number)\n",
    "# RETURNS: nothing\n",
    "def sendToRedis(redisInstance, datasetDict, hashPrefix):\n",
    "    for i in range(1, len(datasetDict)):\n",
    "        for j in range(0, len(datasetDict[0])):\n",
    "            redisInstance.hset(hashPrefix + str(i), datasetDict[0][j], datasetDict[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7b87a",
   "metadata": {},
   "source": [
    "If we desire to remove hashes prefixed with the dataset name, sent to Redis as above explained, we can also reverse the process by looping over the length of the dataset dictionary (the dictionary keys range from 0 to 250k or 500k, etc.), assigning the dataset name + colon + the row number to the hashes we want to remove and applying the <code>delete</code> method on them. This will remove them one by one (a long process as well as the one of loading them). Again, we store the procedure into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29087e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: removes Redis hashes sent with a prefix from a Python dictionary\n",
    "# arguments:a Redis instance, a dictionary(dict), a string we want to use as hash prefix\n",
    "# (usually the hash string ends with a colon to separate prefix and row number)\n",
    "# RETURNS: nothing\n",
    "def removeFromRedis(redisInstance, datasetDict, hashPrefix):\n",
    "    for i in range(1, len(datasetDict)):\n",
    "        redisInstance.delete(hashPrefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE LINES START LONG PROCESSES, SO I COMMENT THEM OUT TO AVOID UNCAUTIOUS USE\n",
    "'''\n",
    "# 250k keys dict to Redis hashes\n",
    "sendToRedis(myRedis, smallDB, 'smallDB:')\n",
    "\n",
    "# 500k keys dict to Redis hashes\n",
    "sendToRedis(myRedis, smallDB, 'mediumDB:')\n",
    "\n",
    "# 750k keys dict to Redis hashes\n",
    "sendToRedis(myRedis, smallDB, 'largeDB:')\n",
    "\n",
    "# 1m keys dict to Redis hashes\n",
    "sendToRedis(myRedis, smallDB, 'humongousDB:')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional delete hashes process\n",
    "# removeFromRedis(myRedis, smallDB, 'smallDB:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295e871",
   "metadata": {},
   "source": [
    "We can consider each hash as a single document in a collection of documents where keys are common across them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f459600",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Executing a query (<i>RediSearch</i>)\n",
    "</h4><br>\n",
    "Queries can be performed by using the <a href = 'https://docs.redis.com/latest/stack/search/'>RediSearch module</a>, which builds indices based on the provided schema.\n",
    "\n",
    "- Creating an index <code>FT.CREATE</code><br>\n",
    "  This is a very important step to take before performing a query. Creating an index allows to define the <code>SCHEMA</code> of the data for the purpose of performing a query. Creating the index is strongly query-oriented. The schema is in fact a list of secondary indices that we base our queries on.<br>\n",
    "<code>\n",
    "    FT.CREATE <i>indexName</i> ON hash PREFIX 1 <i>prefixPattern</i> SCHEMA [<i>fieldName</i> [TYPE] [OPTIONS] ... ]\n",
    "</code>\n",
    "<br>\n",
    "  As the example syntax above shows, we specify:\n",
    "  \n",
    "  - the name of the index we are creating (<i>indexName</i>);\n",
    "  - the data type on which we are creating it (HASH or JSON supported);\n",
    "  - the data prefix (we have a pattern that allows us to put together many data types as a collection);\n",
    "  - the schema, i.e. the fields (hash keys, to be more precise) we want to use as indices followed by the value type (TEXT, NUMERIC, TAG, ...) and its options (SORTABLE, ...).<br><br>\n",
    "\n",
    "- Performing a query <code>FT.SEARCH</code><br>\n",
    "  After having created an index we can use the secondary indices in the schema to select elements based on specific values. \n",
    "<br>\n",
    "<code>\n",
    "    FT.SEARCH <i>indexName</i> '@fieldName:fieldValue' RETURN [nr of projected fields] [<i>fieldNames</i>]\n",
    "</code>\n",
    "<br>\n",
    "  As the example syntax shows, we specify:\n",
    "  \n",
    "  - the name of the index we want to use (<i>indexName</i>);\n",
    "  - the selection criteria (<i>fieldName</i> introduced by a <i><b>at sign (@)</b></i> and <i>fieldValue</i> introduced by a <i><b>colon sign (:)</b></i>);\n",
    "  - the projected fields (introduced by the <code>RETURN</code> keyword and their number)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b61e0",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Executing a query in redis-py\n",
    "</h4><br>\n",
    "Within a Redis connection object, the <code>ft</code> method creates a new object providing methods that replicate the <a href = 'https://redis-py.readthedocs.io/en/stable/redismodules.html#redisearch-commands'>RediSearch commands</a> that we have introduced in the previous paragraph. Like Redis commands for creating data types, they also are only lowercase. We can create as many <i>RediSearch</i> objects as the indices we want to use to perform queries.<br> It is also advisable to import needed dependencies prior to index creation. <code>TextField</code>, <code>NumericField</code>, <code>TagField</code>, specify the value type of the fields included in the schema. The <code>IndexDefinition</code> dependency is needed to specify the common prefix of the Redis data types that must be indexed. The other imported dependency, <code>Query</code>, is useful for the execution of complex queries, allowing to specify parameters that can be chained to one another. Applying a parameter to a <code>Query()</code> object returns a query object. Applying a chained parameter results in applaying it to the query object returned by the preceding attached parameter and so on. The <code>aggregation</code> dependency is needed to perform aggregate queries by passing an <i>aggregation request</i> to the <code>aggregate</code> method of the index object. Finally, the <code>reducers</code> dependency stores methods to reduce aggregation results into a single record by applying appropriate functions such as <i>count</i>, <i>sum</i>, <i>min</i>, <i>max</i>, <i>average</i> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbb2c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from redis.commands.search.field import TextField, NumericField, TagField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.query import Query\n",
    "import redis.commands.search.aggregation as aggregations\n",
    "import redis.commands.search.reducers as reducers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9017bf6",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Create an index\n",
    "</h4><br>\n",
    "An index can be created with the <code>create_index</code> method of any <i>RediSearch</i> object. We can optionally pass the index name as an argument (otherwise a default '<i>idx</i>' name will be used) and assign the <i>RediSearch</i> object to a Python variable. Then we can pass the schema (each field name of the schema must be enclosed within the function that specifies its value type (<code>TextField</code>, <code>NumericField</code>, <code>TagField</code>) and index definition to the index object. The <code>info()</code> method of the index object is useful to retrieve index information.<br>Notice that if we need to redefine a previously created index, we must first drop it with the <code>dropindex</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b70cca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RediSearch object\n",
    "exampleRS = myRedis.ft('idx:exampleIdx')\n",
    "\n",
    "# (if it exists drop and) create index object\n",
    "#exampleRS.dropindex()\n",
    "schema = (TextField('studentID'), TextField('courseID'), TextField('materialID'))\n",
    "index_definition = IndexDefinition(prefix = 'smallDataset:')\n",
    "exampleRS.create_index(schema, index_definition)\n",
    "#redisIdx.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d496ff",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Run the related query\n",
    "</h4><br>\n",
    "A query depends on the previously created index and is performed via the <code>search</code> method of the index object. It is sufficient to pass a query string to the <code>search</code> method, where a query string is simply a string value that can be found in either of the secondary indices in the schema or a string of the form '<i>@fieldName:fieldValue</i>' if we seek to find the value in a specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a0e0df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result{508 total, docs: [Document {'id': 'smallDataset:180027', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '1439', 'firstName': 'Danilo', 'lastName': 'Barbosa', 'dateOfBirth': '1975-9-5', 'genre': 'male', 'country': 'Granada', 'town': 'Santos do Norte', 'email': 'danilo.barbosa@hotmail.com', 'materialID': '32031', 'unit': 'Unit 4', 'materialType': 'lecture slides', 'name': '[SLIDES] Cellular Respiration, Part 1 ', 'dimension': '9', 'accessDate': '2023-05-19'}, Document {'id': 'smallDataset:102996', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '834', 'firstName': 'Geir', 'lastName': 'Brekke', 'dateOfBirth': '1993-10-22', 'genre': 'male', 'country': 'Republic of the Congo', 'town': 'Trondberg', 'email': 'geir.brekke@yahoo.com', 'materialID': '31985', 'unit': 'Unit 1', 'materialType': 'video lecture', 'name': '[VIDEO] Assessing Breath Sounds Demonstration', 'dimension': '5', 'accessDate': '2023-01-03'}, Document {'id': 'smallDataset:90386', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '735', 'firstName': 'Jeffrey', 'lastName': 'Wheeler', 'dateOfBirth': '1988-3-26', 'genre': 'male', 'country': 'Djibouti', 'town': 'Port Barbara', 'email': 'jeffrey.wheeler@yahoo.com', 'materialID': '32029', 'unit': 'Unit 4', 'materialType': 'lecture slides', 'name': '[SLIDES] Video Prototyping', 'dimension': '9', 'accessDate': '2023-08-21'}, Document {'id': 'smallDataset:90405', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '735', 'firstName': 'Jeffrey', 'lastName': 'Wheeler', 'dateOfBirth': '1988-3-26', 'genre': 'male', 'country': 'Djibouti', 'town': 'Port Barbara', 'email': 'jeffrey.wheeler@yahoo.com', 'materialID': '32053', 'unit': 'Unit 6', 'materialType': 'lecture slides', 'name': '[SLIDES] Negative Externalities', 'dimension': '9', 'accessDate': '2023-07-04'}, Document {'id': 'smallDataset:86714', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '709', 'firstName': 'Jordan', 'lastName': 'Cole', 'dateOfBirth': '1994-9-24', 'genre': 'male', 'country': 'Saint Vincent and the Grenadines', 'town': 'South Maxville', 'email': 'jordan.cole@outlook.com', 'materialID': '32024', 'unit': 'Unit 4', 'materialType': 'video lecture', 'name': '[VIDEO] Maintaining Body Temperature ', 'dimension': '4', 'accessDate': '2022-08-11'}, Document {'id': 'smallDataset:249258', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '1999', 'firstName': 'Sebastião', 'lastName': 'Sousa', 'dateOfBirth': '1988-11-15', 'genre': 'male', 'country': 'Gibraltar', 'town': 'Castelo Branco', 'email': 'sebastião.sousa@clix.pt', 'materialID': '31998', 'unit': 'Unit 2', 'materialType': 'video lecture', 'name': '[VIDEO] Blood Circulation ', 'dimension': '10', 'accessDate': '2022-09-08'}, Document {'id': 'smallDataset:180014', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '1439', 'firstName': 'Danilo', 'lastName': 'Barbosa', 'dateOfBirth': '1975-9-5', 'genre': 'male', 'country': 'Granada', 'town': 'Santos do Norte', 'email': 'danilo.barbosa@hotmail.com', 'materialID': '32016', 'unit': 'Unit 4', 'materialType': 'video lecture', 'name': '[VIDEO] How to Switch Sessions of the Course', 'dimension': '2', 'accessDate': '2023-06-30'}, Document {'id': 'smallDataset:176846', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '1410', 'firstName': 'Candelaria', 'lastName': 'Alba', 'dateOfBirth': '1967-12-19', 'genre': 'non binary', 'country': 'Bangladesh', 'town': 'Badajoz', 'email': 'candelaria.alba@hotmail.com', 'materialID': '31982', 'unit': 'Unit 1', 'materialType': 'lecture slides', 'name': '[SLIDES] Evaluation', 'dimension': '4', 'accessDate': '2023-05-31'}, Document {'id': 'smallDataset:86688', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '709', 'firstName': 'Jordan', 'lastName': 'Cole', 'dateOfBirth': '1994-9-24', 'genre': 'male', 'country': 'Saint Vincent and the Grenadines', 'town': 'South Maxville', 'email': 'jordan.cole@outlook.com', 'materialID': '31994', 'unit': 'Unit 1', 'materialType': 'lecture slides', 'name': '[SLIDES] ', 'dimension': '11', 'accessDate': '2022-03-19'}, Document {'id': 'smallDataset:90395', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '735', 'firstName': 'Jeffrey', 'lastName': 'Wheeler', 'dateOfBirth': '1988-3-26', 'genre': 'male', 'country': 'Djibouti', 'town': 'Port Barbara', 'email': 'jeffrey.wheeler@yahoo.com', 'materialID': '32041', 'unit': 'Unit 5', 'materialType': 'video lecture', 'name': '[VIDEO] A Problem for Arguments', 'dimension': '2', 'accessDate': '2023-07-24'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleRS.search('450')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b72819",
   "metadata": {},
   "source": [
    "A query object stores the integer showing the <b>total number of found documents into the <code>total</code> attribute</b>, the <b>query execution time (in milliseconds) into the <code>duration</code> attribute</b> and all <b>the docs (hashes) matching the selection criteria into the <code>docs</code> attribute.</b> Assigning a query result to a Python variable allows us to retrieve these information at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb88102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query execution time was: 7.215023 milliseconds, and the number of documents matching it is: 508\n",
      "\n",
      "A sample of the courseID and student name for the query results is the following:\n",
      "\n",
      "1 450 Danilo Barbosa\n",
      "2 450 Geir Brekke\n",
      "3 450 Jeffrey Wheeler\n",
      "4 450 Jeffrey Wheeler\n",
      "5 450 Jordan Cole\n",
      "6 450 Sebastião Sousa\n",
      "7 450 Danilo Barbosa\n",
      "8 450 Candelaria Alba\n",
      "9 450 Jordan Cole\n",
      "10 450 Jeffrey Wheeler\n"
     ]
    }
   ],
   "source": [
    "exampleQuery = exampleRS.search('450')\n",
    "print('The query execution time was: %f milliseconds, and the number of documents matching it is: %i\\n' % (exampleQuery.duration, exampleQuery.total))\n",
    "print('A sample of the courseID and student name for the query results is the following:\\n')\n",
    "counter = 0\n",
    "for doc in exampleQuery.docs:\n",
    "    counter += 1\n",
    "    print(counter, doc['courseID'], doc['firstName'], doc['lastName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3e7a7",
   "metadata": {},
   "source": [
    "The above example shows that the value '<i>450</i>' is searched throughout all the secondary indices in the schema of the <i>exampleRS</i> index, so we may  have student IDs, course IDs and material IDs matching the requested value. In the printed results, however, the only field that can match the searched value is the course ID. In the other cases, it may be the student ID or the material ID that we have found matching the searched value, but we cannot tell because the only projected secondary index field is the course ID. The above result also shows a limitation in the query results displayed by Redis. This is controlled by the optional argument <code>LIMIT</code>, which sets the offset and the number of results displayed. The default is 0 10, which returns 10 items starting from the first (0) result. The redis-cli syntax is simply:<br>\n",
    "<code>\n",
    "    FT.SEARCH '<i>@fieldName:fieldValue</i>' LIMIT [first num] RETURN [nr of projected fields] [<i>fieldNames</i>]\n",
    "</code><br>\n",
    "To control this parameter in our Python environment we must implement the query differently. It is not sufficient to pass a string to the <code>search</code> method, but we need to use a <code>Query</code> object as illustrated below. A <code>Query</code> object is used for complex queries allowing to specify parameters on the object itself. Query object parameters can be chained to adapt the query results to our needs. One of the parameters is <code>paging(<i>first</i>, <i>num</i>)</code> which replicates the effects of the <code>LIMIT</code> argument in redis-cli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa014897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 450 Danilo Barbosa\n",
      "2 450 Geir Brekke\n",
      "3 450 Jeffrey Wheeler\n",
      "4 450 Jeffrey Wheeler\n",
      "5 450 Jordan Cole\n",
      "6 450 Sebastião Sousa\n",
      "7 450 Danilo Barbosa\n",
      "8 450 Candelaria Alba\n",
      "9 450 Jordan Cole\n",
      "10 450 Jeffrey Wheeler\n",
      "11 313 Walentina Bohnbach\n",
      "12 313 Walentina Bohnbach\n",
      "13 450 Candelaria Alba\n",
      "14 450 Sebastião Sousa\n",
      "15 450 Sebastião Sousa\n"
     ]
    }
   ],
   "source": [
    "exampleQuery2 = exampleRS.search(Query('450').paging(0, 15))\n",
    "counter2 = 0\n",
    "for doc in exampleQuery2.docs:\n",
    "    counter2 += 1\n",
    "    print(counter2, doc['courseID'], doc['firstName'], doc['lastName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe787d",
   "metadata": {},
   "source": [
    "Instead of retrieving the entire documents, if we are perfectly aware of the information we need from a query, we can project the required fields and save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33553633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of the courseID and student name for the query results is the following:\n",
      "\n",
      "1 313 Walentina Bohnbach\n",
      "2 313 Walentina Bohnbach\n",
      "3 313 Walentina Bohnbach\n",
      "4 313 Walentina Bohnbach\n",
      "5 161 Walentina Bohnbach\n",
      "6 161 Walentina Bohnbach\n",
      "7 313 Walentina Bohnbach\n",
      "8 161 Walentina Bohnbach\n",
      "9 313 Walentina Bohnbach\n",
      "10 313 Walentina Bohnbach\n",
      "11 161 Walentina Bohnbach\n",
      "12 161 Walentina Bohnbach\n",
      "13 313 Walentina Bohnbach\n",
      "14 313 Walentina Bohnbach\n",
      "15 313 Walentina Bohnbach\n"
     ]
    }
   ],
   "source": [
    "exampleQuery3 = exampleRS.search(Query('@studentID:450').return_fields('firstName', 'lastName', 'courseID').paging(0, 15))\n",
    "print('A sample of the courseID and student name for the query results is the following:\\n')\n",
    "counter3 = 0\n",
    "for doc in exampleQuery3.docs:\n",
    "    counter3 += 1\n",
    "    print(counter3, doc['courseID'], doc['firstName'], doc['lastName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b758a62",
   "metadata": {},
   "source": [
    "To avoid replicated results we must use a different type of query, an aggregate query. We use the <code>aggregation</code> dependency to build an aggregation request and the <code>aggregate</code> method to which we pass the aggregation request. Also, we need to set a new index because the schema must support the fields we want to use to perform aggregation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ecad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exampleRS2.dropindex()\n",
    "\n",
    "# new RediSearch object\n",
    "exampleRS2 = myRedis.ft('idx:exampleIdx2')\n",
    "\n",
    "# new index (with new schema)\n",
    "schema2 = (TextField('studentID'), TextField('firstName'), TextField('lastName'))\n",
    "exampleRS2.create_index(schema2, index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599156c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walentina Bohnbach\n"
     ]
    }
   ],
   "source": [
    "# aggregate request and query\n",
    "aggRequest = aggregations.AggregateRequest('@studentID:450').group_by({'@firstName', '@lastName'})\n",
    "exampleQuery4 = exampleRS2.aggregate(aggRequest)\n",
    "for res in exampleQuery4.rows:\n",
    "    print(res[3], res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57940b07",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Measuring and displaying the query execution time\n",
    "</h4><br>\n",
    "To display the query execution time we can use the <code>duration</code> method of a query object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf689977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query execution time was: 6.802797 milliseconds.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AggregateResult' object has no attribute 'duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe query execution time was: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m milliseconds.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m exampleQuery3\u001b[38;5;241m.\u001b[39mduration)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe query execution time was: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m milliseconds.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[43mexampleQuery4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AggregateResult' object has no attribute 'duration'"
     ]
    }
   ],
   "source": [
    "print('The query execution time was: %f milliseconds.' % exampleQuery3.duration)\n",
    "print('The query execution time was: %f milliseconds.' % exampleQuery4.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e21de",
   "metadata": {},
   "source": [
    "However, this method is not available for aggragation objects, so it is better to rely on the <code>time()</code> function of the Python <code>time</code> module to mark the time before and after operations are executed and compute their difference. The unit measure here is seconds, so we get the time execution in milliseconds by multiplying the difference by 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6037ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdac7483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query execution time for exampleQuery3 was: 4.856825 milliseconds.\n",
      "The query execution time for exampleQuery4 was: 3.792048 milliseconds.\n"
     ]
    }
   ],
   "source": [
    "# performing exampleQuery3 again:\n",
    "startEx3 = time()\n",
    "exampleRS.search(Query('@studentID:450').return_fields('firstName', 'lastName', 'courseID').paging(0, 15))\n",
    "endEx3 = time()\n",
    "timeEx3 = (endEx3 - startEx3) * 1000\n",
    "\n",
    "# performing exampleQuery4 again:\n",
    "startEx4 = time()\n",
    "exampleRS2.aggregate(aggRequest)\n",
    "endEx4 = time()\n",
    "timeEx4 = (endEx4 - startEx4) * 1000\n",
    "\n",
    "print('The query execution time for exampleQuery3 was: %f milliseconds.' % timeEx3)\n",
    "print('The query execution time for exampleQuery4 was: %f milliseconds.' % timeEx4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfc876",
   "metadata": {},
   "source": [
    "<h3>Query the datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36027f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallDict = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "mediumDict = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "largeDict = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "humongousDict = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f35cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean function\n",
    "def mean(aList):\n",
    "    n = len(aList)\n",
    "    sum = 0\n",
    "    for value in aList:\n",
    "        sum += value\n",
    "    return sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9518c",
   "metadata": {},
   "source": [
    "<h3>Dataset with 250k records</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4a166",
   "metadata": {},
   "source": [
    "I create a dictionary of lists where the keys are the query names and the values are 31 query executions: I will attach the value of the query execution time of the most recent query (<code>SHOW PROFILE</code> statement) to the list. In particular, I will attach 31 query executions. I will consider the first execution and the mean value of the following 30 executions. Since the values are required in milliseconds, while attaching them, I divide them by 1000 and round them to the fifth decimal precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b5194",
   "metadata": {},
   "source": [
    "<h4>Query1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e527d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RediSearch object\n",
    "small_redis1 = myRedis.ft('small_index1')\n",
    "\n",
    "# (drop and) create index\n",
    "#small_redis1.dropindex()\n",
    "schema1 = (TextField('courseID'), TextField('firstName'), TextField('lastName'))\n",
    "index_definition = IndexDefinition(prefix = ['smallDataset:'], index_type = IndexType.HASH)\n",
    "small_redis1.create_index(schema1, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b134ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result:\n",
      "\n",
      "Leite Patrícia\n",
      "Nicolas Émile\n",
      "Lie Cathrine\n",
      "Gaižauskas Vigilija\n",
      "Amundsen Ingeborg\n",
      "Arenas Casandra\n",
      "Soylu Ledün\n",
      "Laroche Arthur\n",
      "Nicolas Nath\n",
      "Narušis Ana\n",
      "\n",
      "Query execution time in milliseconds:\n",
      "16.279220581054688\n"
     ]
    }
   ],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest1 = aggregations.AggregateRequest('@courseID:192').group_by({'@firstName', '@lastName'})\n",
    "start = time()\n",
    "small_query1 = small_redis1.aggregate(aggRequest1)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in small_query1.rows:\n",
    "    print(res[1], res[3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "smallDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7617aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    small_redis1.aggregate(aggRequest1)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    smallDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1fd0e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [16.27922,\n",
       "  6.15597,\n",
       "  6.5372,\n",
       "  5.46217,\n",
       "  4.84991,\n",
       "  5.18417,\n",
       "  6.09493,\n",
       "  5.25498,\n",
       "  5.41401,\n",
       "  6.77299,\n",
       "  5.94616,\n",
       "  5.58805,\n",
       "  5.88107,\n",
       "  6.3262,\n",
       "  4.92072,\n",
       "  5.63312,\n",
       "  6.00696,\n",
       "  6.35505,\n",
       "  5.70583,\n",
       "  4.34709,\n",
       "  3.95799,\n",
       "  3.59416,\n",
       "  3.90315,\n",
       "  3.81494,\n",
       "  4.03619,\n",
       "  3.80397,\n",
       "  3.97706,\n",
       "  4.01115,\n",
       "  4.143,\n",
       "  3.65019,\n",
       "  3.19791],\n",
       " 'query2': [],\n",
       " 'query3': [],\n",
       " 'query4': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e494b",
   "metadata": {},
   "source": [
    "<h4>Query2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f839320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RediSearch object\n",
    "small_redis2 = myRedis.ft('small_index2')\n",
    "\n",
    "# (drop and) create index\n",
    "#small_redis2.dropindex()\n",
    "schema2 = (TextField('discipline'), TextField('courseYear'), TextField('courseName'))\n",
    "index_definition = IndexDefinition(prefix = ['smallDataset:'], index_type = IndexType.HASH)\n",
    "small_redis2.create_index(schema2, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad5c3b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result:\n",
      "\n",
      "Introduction to Probability and Data with R\n",
      "Basic Statistics\n",
      "Bayesian Statistics: From Concept to Data Analysis\n",
      "Python and Statistics for Financial Analysis\n",
      "Understanding Clinical Research: Behind the Statistics\n",
      "Econometrics: Methods and Applications\n",
      "Exploratory Data Analysis\n",
      "Foundations: Data, Data, Everywhere\n",
      "Introduction to Statistics\n",
      "\n",
      "Query execution time in milliseconds:\n",
      "22.401094436645508\n"
     ]
    }
   ],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest2 = aggregations.AggregateRequest('@discipline:statistics @courseYear:2022').group_by('@courseName')\n",
    "start = time()\n",
    "small_query2 = small_redis2.aggregate(aggRequest2)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in small_query2.rows:\n",
    "    print(res[1])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "smallDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a11999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    small_redis2.aggregate(aggRequest2)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    smallDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1179575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [16.27922,\n",
       "  6.15597,\n",
       "  6.5372,\n",
       "  5.46217,\n",
       "  4.84991,\n",
       "  5.18417,\n",
       "  6.09493,\n",
       "  5.25498,\n",
       "  5.41401,\n",
       "  6.77299,\n",
       "  5.94616,\n",
       "  5.58805,\n",
       "  5.88107,\n",
       "  6.3262,\n",
       "  4.92072,\n",
       "  5.63312,\n",
       "  6.00696,\n",
       "  6.35505,\n",
       "  5.70583,\n",
       "  4.34709,\n",
       "  3.95799,\n",
       "  3.59416,\n",
       "  3.90315,\n",
       "  3.81494,\n",
       "  4.03619,\n",
       "  3.80397,\n",
       "  3.97706,\n",
       "  4.01115,\n",
       "  4.143,\n",
       "  3.65019,\n",
       "  3.19791],\n",
       " 'query2': [22.40109,\n",
       "  19.95373,\n",
       "  17.82703,\n",
       "  18.59808,\n",
       "  20.56193,\n",
       "  23.2172,\n",
       "  24.76096,\n",
       "  18.04614,\n",
       "  24.69683,\n",
       "  28.87392,\n",
       "  30.65395,\n",
       "  21.71397,\n",
       "  15.95473,\n",
       "  14.38427,\n",
       "  11.82222,\n",
       "  11.84297,\n",
       "  12.01987,\n",
       "  12.20703,\n",
       "  11.15012,\n",
       "  11.43909,\n",
       "  13.12399,\n",
       "  12.89296,\n",
       "  13.03506,\n",
       "  14.3919,\n",
       "  13.36718,\n",
       "  13.376,\n",
       "  15.75804,\n",
       "  12.60495,\n",
       "  12.17389,\n",
       "  13.32998,\n",
       "  13.23199],\n",
       " 'query3': [],\n",
       " 'query4': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58288374",
   "metadata": {},
   "source": [
    "<h4>Query3</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff2fd88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RediSearch object\n",
    "small_redis3 = myRedis.ft('small_index3')\n",
    "\n",
    "# (drop and) create index\n",
    "#small_redis3.dropindex()\n",
    "schema3 = (TextField('materialType'), TagField('discipline'), TextField('email'), TextField('firstName'))\n",
    "index_definition = IndexDefinition(prefix = ['smallDataset:'], index_type = IndexType.HASH)\n",
    "small_redis3.create_index(schema3, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc0465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result:\n",
      "\n",
      "632\n",
      "\n",
      "Query execution time in milliseconds:\n",
      "14.388084411621094\n"
     ]
    }
   ],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest3 = aggregations.AggregateRequest('@discipline:{maths} @materialType:\\'lecture slides\\' @email:*gmail.com').group_by('@discipline', reducers.count().alias('count'))\n",
    "start = time()\n",
    "small_query3 = small_redis3.aggregate(aggRequest3)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "print(small_query3.rows[0][3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "smallDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8746f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    small_query3 = small_redis3.aggregate(aggRequest3)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    smallDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d73d6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [16.27922,\n",
       "  6.15597,\n",
       "  6.5372,\n",
       "  5.46217,\n",
       "  4.84991,\n",
       "  5.18417,\n",
       "  6.09493,\n",
       "  5.25498,\n",
       "  5.41401,\n",
       "  6.77299,\n",
       "  5.94616,\n",
       "  5.58805,\n",
       "  5.88107,\n",
       "  6.3262,\n",
       "  4.92072,\n",
       "  5.63312,\n",
       "  6.00696,\n",
       "  6.35505,\n",
       "  5.70583,\n",
       "  4.34709,\n",
       "  3.95799,\n",
       "  3.59416,\n",
       "  3.90315,\n",
       "  3.81494,\n",
       "  4.03619,\n",
       "  3.80397,\n",
       "  3.97706,\n",
       "  4.01115,\n",
       "  4.143,\n",
       "  3.65019,\n",
       "  3.19791],\n",
       " 'query2': [22.40109,\n",
       "  19.95373,\n",
       "  17.82703,\n",
       "  18.59808,\n",
       "  20.56193,\n",
       "  23.2172,\n",
       "  24.76096,\n",
       "  18.04614,\n",
       "  24.69683,\n",
       "  28.87392,\n",
       "  30.65395,\n",
       "  21.71397,\n",
       "  15.95473,\n",
       "  14.38427,\n",
       "  11.82222,\n",
       "  11.84297,\n",
       "  12.01987,\n",
       "  12.20703,\n",
       "  11.15012,\n",
       "  11.43909,\n",
       "  13.12399,\n",
       "  12.89296,\n",
       "  13.03506,\n",
       "  14.3919,\n",
       "  13.36718,\n",
       "  13.376,\n",
       "  15.75804,\n",
       "  12.60495,\n",
       "  12.17389,\n",
       "  13.32998,\n",
       "  13.23199],\n",
       " 'query3': [14.38808,\n",
       "  14.73188,\n",
       "  14.78505,\n",
       "  14.94598,\n",
       "  13.30996,\n",
       "  13.36408,\n",
       "  15.13815,\n",
       "  12.89868,\n",
       "  13.82518,\n",
       "  18.49914,\n",
       "  13.098,\n",
       "  40.06886,\n",
       "  19.76323,\n",
       "  10.71787,\n",
       "  10.88619,\n",
       "  9.35912,\n",
       "  7.98392,\n",
       "  9.18984,\n",
       "  8.02279,\n",
       "  7.91383,\n",
       "  9.0909,\n",
       "  8.37517,\n",
       "  8.19802,\n",
       "  9.0251,\n",
       "  8.23998,\n",
       "  9.56702,\n",
       "  8.94904,\n",
       "  8.65006,\n",
       "  8.00514,\n",
       "  7.99108,\n",
       "  7.82514],\n",
       " 'query4': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea45e5b",
   "metadata": {},
   "source": [
    "<h4>Query4</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8faaba4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RediSearch object\n",
    "small_redis4 = myRedis.ft('small_index4')\n",
    "\n",
    "# (drop and) create index\n",
    "#small_redis4.dropindex()\n",
    "schema4 = (TagField('discipline'), TagField('courseYear'), TextField('country'), TextField('dateOfBirth'), TextField('firstName'), TextField('lastName', sortable = True))\n",
    "index_definition = IndexDefinition(prefix = ['smallDataset:'], index_type = IndexType.HASH)\n",
    "small_redis4.create_index(schema4, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d72e19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result:\n",
      "\n",
      "lie Cathrine South Korea 1986-7-12\n",
      "reynolds Lynda Korea 1989-7-21\n",
      "sura Raghav North Korea 1973-11-27\n",
      "\n",
      "Query execution time in milliseconds:\n",
      "8.751869201660156\n"
     ]
    }
   ],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest4 = aggregations.AggregateRequest('@discipline:{psychology} AND @courseYear:{2023} AND @country:*orea AND -@dateOfBirth:200*').group_by({'@firstName', '@lastName', '@country', '@dateOfBirth'}).sort_by('@lastName')\n",
    "start = time()\n",
    "small_query4 = small_redis4.aggregate(aggRequest4)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in small_query4.rows:\n",
    "    print(res[1], res[5], res[7], res[3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "smallDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "062f2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    small_redis4.aggregate(aggRequest4)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    smallDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4d8467c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [16.27922,\n",
       "  6.15597,\n",
       "  6.5372,\n",
       "  5.46217,\n",
       "  4.84991,\n",
       "  5.18417,\n",
       "  6.09493,\n",
       "  5.25498,\n",
       "  5.41401,\n",
       "  6.77299,\n",
       "  5.94616,\n",
       "  5.58805,\n",
       "  5.88107,\n",
       "  6.3262,\n",
       "  4.92072,\n",
       "  5.63312,\n",
       "  6.00696,\n",
       "  6.35505,\n",
       "  5.70583,\n",
       "  4.34709,\n",
       "  3.95799,\n",
       "  3.59416,\n",
       "  3.90315,\n",
       "  3.81494,\n",
       "  4.03619,\n",
       "  3.80397,\n",
       "  3.97706,\n",
       "  4.01115,\n",
       "  4.143,\n",
       "  3.65019,\n",
       "  3.19791],\n",
       " 'query2': [22.40109,\n",
       "  19.95373,\n",
       "  17.82703,\n",
       "  18.59808,\n",
       "  20.56193,\n",
       "  23.2172,\n",
       "  24.76096,\n",
       "  18.04614,\n",
       "  24.69683,\n",
       "  28.87392,\n",
       "  30.65395,\n",
       "  21.71397,\n",
       "  15.95473,\n",
       "  14.38427,\n",
       "  11.82222,\n",
       "  11.84297,\n",
       "  12.01987,\n",
       "  12.20703,\n",
       "  11.15012,\n",
       "  11.43909,\n",
       "  13.12399,\n",
       "  12.89296,\n",
       "  13.03506,\n",
       "  14.3919,\n",
       "  13.36718,\n",
       "  13.376,\n",
       "  15.75804,\n",
       "  12.60495,\n",
       "  12.17389,\n",
       "  13.32998,\n",
       "  13.23199],\n",
       " 'query3': [14.38808,\n",
       "  14.73188,\n",
       "  14.78505,\n",
       "  14.94598,\n",
       "  13.30996,\n",
       "  13.36408,\n",
       "  15.13815,\n",
       "  12.89868,\n",
       "  13.82518,\n",
       "  18.49914,\n",
       "  13.098,\n",
       "  40.06886,\n",
       "  19.76323,\n",
       "  10.71787,\n",
       "  10.88619,\n",
       "  9.35912,\n",
       "  7.98392,\n",
       "  9.18984,\n",
       "  8.02279,\n",
       "  7.91383,\n",
       "  9.0909,\n",
       "  8.37517,\n",
       "  8.19802,\n",
       "  9.0251,\n",
       "  8.23998,\n",
       "  9.56702,\n",
       "  8.94904,\n",
       "  8.65006,\n",
       "  8.00514,\n",
       "  7.99108,\n",
       "  7.82514],\n",
       " 'query4': [8.75187,\n",
       "  7.95031,\n",
       "  6.44732,\n",
       "  6.39009,\n",
       "  5.88417,\n",
       "  5.82409,\n",
       "  6.08492,\n",
       "  7.03716,\n",
       "  5.99122,\n",
       "  5.38707,\n",
       "  5.62,\n",
       "  7.73811,\n",
       "  6.30498,\n",
       "  7.33995,\n",
       "  6.74105,\n",
       "  6.05178,\n",
       "  5.67913,\n",
       "  6.67024,\n",
       "  6.27089,\n",
       "  5.31507,\n",
       "  5.29313,\n",
       "  5.69201,\n",
       "  7.07293,\n",
       "  5.42998,\n",
       "  5.36895,\n",
       "  31.25095,\n",
       "  7.00998,\n",
       "  9.80878,\n",
       "  9.64189,\n",
       "  5.19323,\n",
       "  4.79198]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "823f453f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [16.27922, 5.01754],\n",
       " 'query2': [22.40109, 16.567],\n",
       " 'query3': [14.38808, 12.08061],\n",
       " 'query4': [8.75187, 7.24271]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDataset = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "for key in smallDict:\n",
    "    smallDataset[key].append(smallDict[key][0])\n",
    "    mean30 = mean(smallDict[key][1 : 31])\n",
    "    smallDataset[key].append(round(mean30, 5))\n",
    "smallDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd304ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77c44e9e",
   "metadata": {},
   "source": [
    "<h3>Dataset with 500k records</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3a161",
   "metadata": {},
   "source": [
    "<h4>Query1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da4cbbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RediSearch object\n",
    "medium_redis1 = myRedis.ft('medium_index1')\n",
    "\n",
    "# (drop and) create index\n",
    "medium_redis1.dropindex()\n",
    "schema1 = (TextField('courseID'), TextField('firstName'), TextField('lastName'))\n",
    "index_definition = IndexDefinition(prefix = ['mediumDataset:'], index_type = IndexType.HASH)\n",
    "medium_redis1.create_index(schema1, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea9ba9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result:\n",
      "\n",
      "\n",
      "Query execution time in milliseconds:\n",
      "3.821134567260742\n"
     ]
    }
   ],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest1 = aggregations.AggregateRequest('@courseID:192').group_by({'@firstName', '@lastName'})\n",
    "start = time()\n",
    "medium_query1 = medium_redis1.aggregate(aggRequest1)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in medium_query1.rows:\n",
    "    print(res[1], res[3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "mediumDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ade069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    medium_redis1.aggregate(aggRequest1)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    mediumDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc416234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [7.02071, 10.00214, 7.14111],\n",
       " 'query2': [],\n",
       " 'query3': [],\n",
       " 'query4': []}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediumDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a974e2d",
   "metadata": {},
   "source": [
    "<h4>Query2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37559352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "medium_redis2 = myRedis.ft('medium_index2')\n",
    "\n",
    "# (drop and) create index\n",
    "#medium_redis2.dropindex()\n",
    "schema2 = (TextField('discipline'), TextField('courseYear'), TextField('courseName'))\n",
    "index_definition = IndexDefinition(prefix = ['mediumDataset:'], index_type = IndexType.HASH)\n",
    "medium_redis2.create_index(schema2, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9289561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest2 = aggregations.AggregateRequest('@discipline:statistics @courseYear:2022').group_by('@courseName')\n",
    "start = time()\n",
    "medium_query2 = medium_redis2.aggregate(aggRequest2)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in medium_query2.rows:\n",
    "    print(res[1])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "mediumDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d88ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    medium_redis2.aggregate(aggRequest2)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    mediumDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediumDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682250de",
   "metadata": {},
   "source": [
    "<h4>Query3</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7df7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "medium_redis3 = myRedis.ft('medium_index3')\n",
    "\n",
    "# (drop and) create index\n",
    "#medium_redis3.dropindex()\n",
    "schema3 = (TextField('materialType'), TagField('discipline'), TextField('email'), TextField('firstName'))\n",
    "index_definition = IndexDefinition(prefix = ['mediumDataset:'], index_type = IndexType.HASH)\n",
    "medium_redis3.create_index(schema3, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest3 = aggregations.AggregateRequest('@discipline:{maths} @materialType:\\'lecture slides\\' @email:*gmail.com').group_by('@discipline', reducers.count().alias('count'))\n",
    "start = time()\n",
    "medium_query3 = medium_redis3.aggregate(aggRequest3)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "print(medium_query3.rows[0][3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "mediumDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    medium_query3 = small_redis3.aggregate(aggRequest3)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    mediumDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80204d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediumDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3547309",
   "metadata": {},
   "source": [
    "<h4>Query4</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac194884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "medium_redis4 = myRedis.ft('medium_index4')\n",
    "\n",
    "# (drop and) create index\n",
    "#medium_redis4.dropindex()\n",
    "schema4 = (TagField('discipline'), TagField('courseYear'), TextField('country'), TextField('dateOfBirth'), TextField('firstName'), TextField('lastName', sortable = True))\n",
    "index_definition = IndexDefinition(prefix = ['mediumDataset:'], index_type = IndexType.HASH)\n",
    "medium_redis4.create_index(schema4, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841811fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest4 = aggregations.AggregateRequest('@discipline:{psychology} AND @courseYear:{2023} AND @country:*orea AND -@dateOfBirth:200*').group_by({'@firstName', '@lastName', '@country', '@dateOfBirth'}).sort_by('@lastName')\n",
    "start = time()\n",
    "medium_query4 = medium_redis4.aggregate(aggRequest4)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in medium_query4.rows:\n",
    "    print(res[1], res[5], res[7], res[3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "mediumDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    medium_redis4.aggregate(aggRequest4)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    mediumDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediumDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8201f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediumDataset = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "for key in mediumDict:\n",
    "    mediumDataset[key].append(mediumDict[key][0])\n",
    "    mean30 = mean(mediumDict[key][1 : 31])\n",
    "    mediumDataset[key].append(round(mean30, 5))\n",
    "mediumDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cce339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01589279",
   "metadata": {},
   "source": [
    "<h3>Dataset with 750k records</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9bebe",
   "metadata": {},
   "source": [
    "<h4>Query1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b88301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "large_redis1 = myRedis.ft('large_index1')\n",
    "\n",
    "# (drop and) create index\n",
    "#large_redis1.dropindex()\n",
    "schema1 = (TextField('courseID'), TextField('firstName'), TextField('lastName'))\n",
    "index_definition = IndexDefinition(prefix = ['largeDataset:'], index_type = IndexType.HASH)\n",
    "large_redis1.create_index(schema1, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest1 = aggregations.AggregateRequest('@courseID:192').group_by({'@firstName', '@lastName'})\n",
    "start = time()\n",
    "large_query1 = large_redis1.aggregate(aggRequest1)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in large_query1.rows:\n",
    "    print(res[1], res[3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "largeDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7532d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    large_redis1.aggregate(aggRequest1)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    largeDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5113dd53",
   "metadata": {},
   "source": [
    "<h4>Query2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b821fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "large_redis2 = myRedis.ft('large_index2')\n",
    "\n",
    "# (drop and) create index\n",
    "#large_redis2.dropindex()\n",
    "schema2 = (TextField('discipline'), TextField('courseYear'), TextField('courseName'))\n",
    "index_definition = IndexDefinition(prefix = ['largeDataset:'], index_type = IndexType.HASH)\n",
    "large_redis2.create_index(schema2, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest2 = aggregations.AggregateRequest('@discipline:statistics @courseYear:2022').group_by('@courseName')\n",
    "start = time()\n",
    "large_query2 = large_redis2.aggregate(aggRequest2)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in large_query2.rows:\n",
    "    print(res[1])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "largeDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839dc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    large_redis2.aggregate(aggRequest2)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    largeDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f96b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bef09",
   "metadata": {},
   "source": [
    "<h4>Query3</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ad233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "large_redis3 = myRedis.ft('large_index3')\n",
    "\n",
    "# (drop and) create index\n",
    "#large_redis3.dropindex()\n",
    "schema3 = (TextField('materialType'), TagField('discipline'), TextField('email'), TextField('firstName'))\n",
    "index_definition = IndexDefinition(prefix = ['largeDataset:'], index_type = IndexType.HASH)\n",
    "large_redis3.create_index(schema3, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest3 = aggregations.AggregateRequest('@discipline:{maths} @materialType:\\'lecture slides\\' @email:*gmail.com').group_by('@discipline', reducers.count().alias('count'))\n",
    "start = time()\n",
    "large_query3 = large_redis3.aggregate(aggRequest3)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "print(large_query3.rows[0][3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "largeDict['query3'].append(round(msec_duration, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    large_query3 = large_redis3.aggregate(aggRequest3)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    largeDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f607a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2613b0",
   "metadata": {},
   "source": [
    "<h4>Query4</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130202a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "large_redis4 = myRedis.ft('large_index4')\n",
    "\n",
    "# (drop and) create index\n",
    "#large_redis4.dropindex()\n",
    "schema4 = (TagField('discipline'), TagField('courseYear'), TextField('country'), TextField('dateOfBirth'), TextField('firstName'), TextField('lastName', sortable = True))\n",
    "index_definition = IndexDefinition(prefix = ['largeDataset:'], index_type = IndexType.HASH)\n",
    "large_redis4.create_index(schema4, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f68130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest4 = aggregations.AggregateRequest('@discipline:{psychology} AND @courseYear:{2023} AND @country:*orea AND -@dateOfBirth:200*').group_by({'@firstName', '@lastName', '@country', '@dateOfBirth'}).sort_by('@lastName')\n",
    "start = time()\n",
    "large_query4 = large_redis4.aggregate(aggRequest4)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in large_query4.rows:\n",
    "    print(res[1], res[5], res[7], res[3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "largeDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975836c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    large_redis4.aggregate(aggRequest4)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    largeDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ef3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeDataset = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "for key in largeDict:\n",
    "    largeDataset[key].append(largeDict[key][0])\n",
    "    mean30 = mean(largeDict[key][1 : 31])\n",
    "    largeDataset[key].append(round(mean30, 5))\n",
    "largeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca6223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6a0d952",
   "metadata": {},
   "source": [
    "<h3>Dataset with 1m records</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6f33d",
   "metadata": {},
   "source": [
    "<h4>Query1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2284a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "humongous_redis1 = myRedis.ft('humongous_index1')\n",
    "\n",
    "# (drop and) create index\n",
    "#humongous_redis1.dropindex()\n",
    "schema1 = (TextField('courseID'), TextField('firstName'), TextField('lastName'))\n",
    "index_definition = IndexDefinition(prefix = ['humongousDataset:'], index_type = IndexType.HASH)\n",
    "humongous_redis1.create_index(schema1, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d902b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest1 = aggregations.AggregateRequest('@courseID:192').group_by({'@firstName', '@lastName'})\n",
    "start = time()\n",
    "humongous_query1 = humongous_redis1.aggregate(aggRequest1)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in humongous_query1.rows:\n",
    "    print(res[1], res[3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "humongousDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d81141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    humongous_redis1.aggregate(aggRequest1)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    humongousDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a582b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "humongousDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76372f",
   "metadata": {},
   "source": [
    "<h4>Query2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "humongous_redis2 = myRedis.ft('humongous_index2')\n",
    "\n",
    "# (drop and) create index\n",
    "#humongous_redis2.dropindex()\n",
    "schema2 = (TextField('discipline'), TextField('courseYear'), TextField('courseName'))\n",
    "index_definition = IndexDefinition(prefix = ['humongousDataset:'], index_type = IndexType.HASH)\n",
    "humongous_redis2.create_index(schema2, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest2 = aggregations.AggregateRequest('@discipline:statistics @courseYear:2022').group_by('@courseName')\n",
    "start = time()\n",
    "humongous_query2 = humongous_redis2.aggregate(aggRequest2)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in humongous_query2.rows:\n",
    "    print(res[1])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "humongousDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    humongous_redis2.aggregate(aggRequest2)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    humongousDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "humongousDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d27d4",
   "metadata": {},
   "source": [
    "<h4>Query3</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dacb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "humongous_redis3 = myRedis.ft('humongous_index3')\n",
    "\n",
    "# (drop and) create index\n",
    "#humongous_redis3.dropindex()\n",
    "schema3 = (TextField('materialType'), TagField('discipline'), TextField('email'), TextField('firstName'))\n",
    "index_definition = IndexDefinition(prefix = ['humongousDataset:'], index_type = IndexType.HASH)\n",
    "humongous_redis3.create_index(schema3, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5aef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest3 = aggregations.AggregateRequest('@discipline:{maths} @materialType:\\'lecture slides\\' @email:*gmail.com').group_by('@discipline', reducers.count().alias('count'))\n",
    "start = time()\n",
    "humongous_query3 = humongous_redis3.aggregate(aggRequest3)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "print(humongous_query3.rows[0][3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "humongousDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    humongous_query3 = small_redis3.aggregate(aggRequest3)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    humongousDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613aa929",
   "metadata": {},
   "outputs": [],
   "source": [
    "humongousDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74347821",
   "metadata": {},
   "source": [
    "<h4>Query4</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef01a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RediSearch object\n",
    "humongous_redis4 = myRedis.ft('humongous_index4')\n",
    "\n",
    "# (drop and) create index\n",
    "#humongous_redis4.dropindex()\n",
    "schema4 = (TagField('discipline'), TagField('courseYear'), TextField('country'), TextField('dateOfBirth'), TextField('firstName'), TextField('lastName', sortable = True))\n",
    "index_definition = IndexDefinition(prefix = ['humongousDataset:'], index_type = IndexType.HASH)\n",
    "humongous_redis4.create_index(schema4, definition = index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform and show query (and measure time)\n",
    "aggRequest4 = aggregations.AggregateRequest('@discipline:{psychology} AND @courseYear:{2023} AND @country:*orea AND -@dateOfBirth:200*').group_by({'@firstName', '@lastName', '@country', '@dateOfBirth'}).sort_by('@lastName')\n",
    "start = time()\n",
    "humongous_query4 = humongous_redis4.aggregate(aggRequest4)\n",
    "end = time()\n",
    "msec_duration = (end - start) * 1000\n",
    "\n",
    "print('Query result:\\n')\n",
    "for res in humongous_query4.rows:\n",
    "    print(res[1], res[5], res[7], res[3])\n",
    "print('\\nQuery execution time in milliseconds:\\n' + str(msec_duration))\n",
    "humongousDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1774b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query 30 more times\n",
    "for i in range(0, 30):\n",
    "    start = time()\n",
    "    humongous_redis4.aggregate(aggRequest4)\n",
    "    end = time()\n",
    "    msec_duration = (end - start) * 1000\n",
    "    humongousDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ca463",
   "metadata": {},
   "outputs": [],
   "source": [
    "humongousDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb719b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "humongousDataset = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "for key in humongousDict:\n",
    "    humongousDataset[key].append(humongousDict[key][0])\n",
    "    mean30 = mean(humongousDict[key][1 : 31])\n",
    "    humongousDataset[key].append(round(mean30, 5))\n",
    "humongousDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d40f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('redis_tests.csv', 'w', newline = '') as redis_tests:\n",
    "    writer = csv.writer(redis_tests, delimiter = ',')\n",
    "    keys = smallDataset.keys()\n",
    "    limit = len(smallDataset['query1'])\n",
    "    \n",
    "    writer.writerow(keys)\n",
    "    writer.writerow('s') # s stands for small dataset\n",
    "    for i in range(0, limit):\n",
    "        writer.writerow(smallDataset[k][i] for k in keys)\n",
    "    writer.writerow('m')  # m stands for medium dataset\n",
    "    for i in range(0, limit):\n",
    "        writer.writerow(mediumDataset[k][i] for k in keys)\n",
    "    writer.writerow('l') # l stands for large dataset\n",
    "    for i in range(0, limit):\n",
    "        writer.writerow(largeDataset[k][i] for k in keys)\n",
    "    writer.writerow('h') # h stands for humongous dataset\n",
    "    for i in range(0, limit):\n",
    "        writer.writerow(humongousDataset[k][i] for k in keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024a724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
