{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b658c051",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h2>Online learning platform database - Cassandra</h2>\n",
    "    <h3>Performing the queries and storing the queries execution time</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe4135",
   "metadata": {},
   "source": [
    "<h3>Python - Cassandra interaction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad76a4",
   "metadata": {},
   "source": [
    "Prior to performing the queries we import the required modules (the Cassandra Python driver and the <i>time</i> and <i>csv</i> modules), establish a connection with the Cassandra instance running in Docker and choose the keyspace on which we will perform the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5469de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster   # MySQL driver\n",
    "import time                             # time-related functions to register query execution times\n",
    "import csv                              # read and write csv files\n",
    "\n",
    "# instantiate a cluster\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "# create a session by connecting to the cluster\n",
    "session = cluster.connect()\n",
    "\n",
    "# associate a keyspace to the session\n",
    "session.set_keyspace('dbb_cassandra_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd35a9",
   "metadata": {},
   "source": [
    "<h3>Query the datasets</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3e219",
   "metadata": {},
   "source": [
    "I create a dictionary of lists for each of the four keyspaces. In these dictionaries the keys are the query names and the values are the 31 query execution times: in fact I attach the value of the query execution time of the most recent query to the list. Since query execution times are required in milliseconds, prior to attaching them, I multiply them by 1000 and round them to the fifth decimal precision.\n",
    "The above summarized actions (for each of the four queries on each of the four keyspaces) are performed by following a standard succession of steps. Each step is encapsulated within a notebook cell (so each query is performed 31 times by using three notebook cells), as follows:\n",
    " - step 1: create index if needed, define the query, perform it for the first time, contextually create timestamps prior and after query execution, print query result;\n",
    " - step 2: compute execution time of the first query execution and store it within the corresponding dictionary list;\n",
    " - step 3: [thirty times] perform query execution while creating prior and following timestamps, compute execution time and store it within the corresponding dictionary list <u>, reset the cursor to allow repeating the query</u>.\n",
    "\n",
    "For each dataset, after having performed the four queries, I will finally compute the mean of the query executions from step 3. Together with the first query execution, this mean value will be stored into a new dictionary, specific to a dataset. Originally, I would use these four new dictionaries to save the query execution times into a csv file for constructing histograms. I later resolved to save all the 31 recorded query execution times and pass them all to Microsoft© Excel to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9306785",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallDict = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "mediumDict = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "largeDict = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}\n",
    "humongousDict = {'query1' : list(), 'query2' : list(), 'query3' : list(), 'query4' : list()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24ae58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean function (used to compute mean execution time of the 30 grouped queries)\n",
    "def mean(aList):\n",
    "    n = len(aList)\n",
    "    sum = 0\n",
    "    for value in aList:\n",
    "        sum += value\n",
    "    return sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcc9487",
   "metadata": {},
   "source": [
    "<h3>Table with 250k records</h3><br>\n",
    "I start with the smallest table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514df0ff",
   "metadata": {},
   "source": [
    "<h4>Query1</h4>\n",
    "It is to be noted that, in relation to its focus on performance, Cassandra does not allow the use of the <code>DISTINCT</code> keyword on columns that are not partition keys (primary keys). In <i>Query 1</i>, however, we are only interested in the names of the students enrolled to the course having ID = 192, there is no point in having a student's name repeated more than once. Each student enrolled to course 192, however, has accessed to various learning materials of course 192, hence the query result, without the use of <code>DISTINCT</code> will be a <i>bag</i>, rather than a <i>set</i>. Duplicate values must be handled in some way, in order to display each student only once. I have considered two possibilities to reach the desired result:\n",
    "\n",
    "- the first one uses CQLSH and an external csv file. It requires, within the selected keyspace, creating a new table with three fields (student first name, student last name and course ID) and setting the first two as primary key. Then the same three fields are to be copied from the entire original table to a csv file and copied back from the csv file to the table having firstname and lastName as primary key. Then the query on the new table can be run by using the <code>DISTINCT</code> option:\n",
    "\n",
    "    <code>\n",
    "        'CREATE TABLE query1_temp (firstName VARCHAR, lastName VARCHAR, courseID VARCHAR, PRIMARY KEY(firstName, lastName));'\n",
    "        'COPY smallDB(firstName, lastName, courseID) TO 'path/query1_temp.csv' WITH HEADER = TRUE AND DELIMITER = ',';'\n",
    "        'COPY query1_temp(firstname, lastName, courseID) FROM 'path/query1_temp.csv' WITH HEADER = TRUE AND DELIMITER = ',';'\n",
    "        'SELECT DISTINCT firstName, lastName FROM query1_temp WHERE courseID = 192;'\n",
    "    </code>\n",
    "\n",
    "- the second one just considers performing the query on the original table without the use of the <code>DISTINCT</code> keyword. The query result is then processed via programming language to obtain the unique values of the students enrolled to course 192. Python is suitable for this purpose, having in store set objects than do not allow element replicas.\n",
    "\n",
    "Both methods will affect the query execution time, if all the steps are to be taken into account. The second method seems to me the cleanest one and I will apply it for <i>Query 1</i>. In particular, I will add to <i>step 1</i> a new substep: prior to recording timestamps I create a set (<i>resSet</i>) where I want to store unique values from the query result. After having defined thid object and created the index required by the query: I record the first timestamp, I run the query, I manipulate the query result by storing the rows into the <i>resSet</i> object, I record the last timestamp. Then the query result can be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5eeb8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casandra Arenas\n",
      "Ledün Soylu\n",
      "Patrícia Leite\n",
      "Vigilija Gaižauskas\n",
      "Narciso Ferrán\n",
      "Sarah Lara\n",
      "Nath Nicolas\n",
      "Cathrine Lie\n",
      "Custodia Hidalgo\n",
      "Émile Nicolas\n",
      "Ana Narušis\n",
      "Ingeborg Amundsen\n",
      "Arthur Laroche\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "resSet1 = set()\n",
    "session.execute('CREATE INDEX IF NOT EXISTS query1Index ON smalldb(courseid);')\n",
    "small_cassandra1 = 'SELECT firstName, lastName FROM smalldb WHERE courseid = \\'192\\';'\n",
    "\n",
    "before = time.time()\n",
    "small_query1 = session.execute(small_cassandra1)\n",
    "for row in small_query1:\n",
    "    resSet1.add(row)\n",
    "after = time.time()\n",
    "\n",
    "for element in resSet1:\n",
    "    print(element[0], element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e7d2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2\n",
    "msec_duration = (after - before) * 1000\n",
    "smallDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81b36cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3\n",
    "for i in range(0, 30):\n",
    "    resSet1 = set()\n",
    "    before = time.time()\n",
    "    small_query1 = session.execute(small_cassandra1)\n",
    "    for row in small_query1:\n",
    "        resSet1.add(row)\n",
    "    after = time.time()\n",
    "    msec_duration = (after - before) * 1000\n",
    "    smallDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23675f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [82.04389,\n",
       "  75.12617,\n",
       "  47.38998,\n",
       "  43.33997,\n",
       "  37.53185,\n",
       "  50.21596,\n",
       "  58.46024,\n",
       "  53.57504,\n",
       "  44.61384,\n",
       "  56.72574,\n",
       "  67.25574,\n",
       "  62.52623,\n",
       "  74.18704,\n",
       "  54.96001,\n",
       "  38.90896,\n",
       "  55.60422,\n",
       "  50.2069,\n",
       "  54.97217,\n",
       "  49.22771,\n",
       "  43.29991,\n",
       "  64.61501,\n",
       "  41.8992,\n",
       "  40.11822,\n",
       "  41.27002,\n",
       "  45.6481,\n",
       "  58.4147,\n",
       "  51.157,\n",
       "  61.58209,\n",
       "  57.70183,\n",
       "  63.97605,\n",
       "  66.19596],\n",
       " 'query2': [],\n",
       " 'query3': [],\n",
       " 'query4': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394caa25",
   "metadata": {},
   "source": [
    "<h4>Query 2</h4>\n",
    "<i>Query 2</i> requires selection on more than one field value (discipline must be 'statistics' and the year of the course must be '2022'. In this case two indices must be created, but Cassandra requires the <code>ALLOW FILTERING</code> clause because double indexing may negatively impact query performance. Even in this case we need unique values, hence I add results to a Python set after query completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fadb176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploratory Data Analysis\n",
      "Introduction to Probability and Data with R\n",
      "Bayesian Statistics: From Concept to Data Analysis\n",
      "Foundations: Data, Data, Everywhere\n",
      "Econometrics: Methods and Applications\n",
      "Basic Statistics\n",
      "Introduction to Statistics\n",
      "Python and Statistics for Financial Analysis\n",
      "Understanding Clinical Research: Behind the Statistics\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "resSet2 = set()\n",
    "session.execute('CREATE INDEX IF NOT EXISTS query2Index1 ON smalldb(discipline);')\n",
    "session.execute('CREATE INDEX IF NOT EXISTS query2Index2 ON smalldb(courseyear);')\n",
    "small_cassandra2 = 'SELECT coursename FROM smalldb WHERE discipline = \\'statistics\\' AND courseyear = \\'2022\\' ALLOW FILTERING;'\n",
    "\n",
    "before = time.time()\n",
    "small_query2 = session.execute(small_cassandra2)\n",
    "for row in small_query2:\n",
    "    resSet2.add(row)\n",
    "after = time.time()\n",
    "\n",
    "for element in resSet2:\n",
    "    print(element[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99130a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2\n",
    "msec_duration = (after - before) * 1000\n",
    "smallDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "898ce77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3\n",
    "for i in range(0, 30):\n",
    "    before = time.time()\n",
    "    small_query2 = session.execute(small_cassandra2)\n",
    "    for row in small_query2:\n",
    "        resSet2.add(row)\n",
    "    after = time.time()\n",
    "    msec_duration = (after - before) * 1000\n",
    "    smallDict['query2'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2476243a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [82.04389,\n",
       "  75.12617,\n",
       "  47.38998,\n",
       "  43.33997,\n",
       "  37.53185,\n",
       "  50.21596,\n",
       "  58.46024,\n",
       "  53.57504,\n",
       "  44.61384,\n",
       "  56.72574,\n",
       "  67.25574,\n",
       "  62.52623,\n",
       "  74.18704,\n",
       "  54.96001,\n",
       "  38.90896,\n",
       "  55.60422,\n",
       "  50.2069,\n",
       "  54.97217,\n",
       "  49.22771,\n",
       "  43.29991,\n",
       "  64.61501,\n",
       "  41.8992,\n",
       "  40.11822,\n",
       "  41.27002,\n",
       "  45.6481,\n",
       "  58.4147,\n",
       "  51.157,\n",
       "  61.58209,\n",
       "  57.70183,\n",
       "  63.97605,\n",
       "  66.19596],\n",
       " 'query2': [355.6149,\n",
       "  300.19498,\n",
       "  307.863,\n",
       "  290.27891,\n",
       "  306.96201,\n",
       "  286.4759,\n",
       "  327.95,\n",
       "  331.97594,\n",
       "  303.18809,\n",
       "  347.83101,\n",
       "  315.45591,\n",
       "  340.63697,\n",
       "  329.01716,\n",
       "  469.95592,\n",
       "  283.3631,\n",
       "  346.22002,\n",
       "  298.14911,\n",
       "  349.04981,\n",
       "  321.83909,\n",
       "  351.92919,\n",
       "  296.23199,\n",
       "  314.04996,\n",
       "  307.90281,\n",
       "  308.39276,\n",
       "  287.75907,\n",
       "  308.87985,\n",
       "  290.93719,\n",
       "  304.68106,\n",
       "  300.45891,\n",
       "  304.76594,\n",
       "  408.48303],\n",
       " 'query3': [],\n",
       " 'query4': []}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca372019",
   "metadata": {},
   "source": [
    "<h4>Query 3</h4>\n",
    "In this case the hardest difficulty was in trying to implement an index that could behave similarly to the MySQL <code>LIKE</code>, by matching patterns in string. In Cassandra custom indices can be created, in particular the so-called <a href = 'https://cassandra.apache.org/doc/stable/cassandra/cql/SASI.html'>SASI indexes</a> which can be set on three different modes: <code>PREFIX</code> (default), <code>CONTAINS</code> or <code>SPARSE</code>.<br>\n",
    "<br>\n",
    "The first one allows use of a syntax such as the following:<br>\n",
    "<code>SELECT <i>fieldNames</i> WHERE <i>fieldName</i> LIKE '<i>prefix</i>%;'</code><br>\n",
    "<br>\n",
    "The second one would allow either suffixes or strings contained in another string:\n",
    "<br>\n",
    "<code>SELECT <i>fieldNames</i> WHERE <i>fieldName</i> LIKE '%<i>contained</i>%;'</code><br>\n",
    "or\n",
    "<br>\n",
    "<code>SELECT <i>fieldNames</i> WHERE <i>fieldName</i> LIKE '%<i>suffix</i>;'</code><br>\n",
    "\n",
    "As for the <code>SPARSE </code> mode, I just found <a href = 'https://www.doanduyhai.com/blog/?p=2058'>here</a> some details. This mode is mainly designed for cases when very few occurrences match the query.<br>\n",
    "Based on this, I approached the definition of <i>Query 3</i> as per the following cell. I create two indices working on the <i>discipline</i> and on the <i>material type</i> and another custom index for the <i>email</i> field. Then I build the <code>WHERE</code> clause on the three indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2dabe277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ReadFailure",
     "evalue": "Error from server: code=1300 [Replica(s) failed to execute read] message=\"Operation failed - received 0 responses and 1 failures: UNKNOWN from /172.25.0.2:7000\" info={'consistency': 'LOCAL_ONE', 'required_responses': 1, 'received_responses': 0, 'failures': 1, 'error_code_map': {'172.25.0.2': '0x0000'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadFailure\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECT materialid FROM smalldb WHERE discipline = \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mmaths\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m AND materialtype = \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mlecture slides\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m AND email LIKE \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m%g\u001b[39;00m\u001b[38;5;124mmail.com\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m ALLOW FILTERING;\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# run the query\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m smallqueryTest_query3 \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cassandra/cluster.py:2637\u001b[0m, in \u001b[0;36mcassandra.cluster.Session.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cassandra/cluster.py:4920\u001b[0m, in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mReadFailure\u001b[0m: Error from server: code=1300 [Replica(s) failed to execute read] message=\"Operation failed - received 0 responses and 1 failures: UNKNOWN from /172.25.0.2:7000\" info={'consistency': 'LOCAL_ONE', 'required_responses': 1, 'received_responses': 0, 'failures': 1, 'error_code_map': {'172.25.0.2': '0x0000'}}"
     ]
    }
   ],
   "source": [
    "# set the indices\n",
    "session.execute('CREATE INDEX IF NOT EXISTS query3Index1 ON smalldb(discipline);')\n",
    "session.execute('CREATE INDEX IF NOT EXISTS query3Index2 ON smalldb(materialtype);')\n",
    "session.execute('CREATE CUSTOM INDEX IF NOT EXISTS SASIquery3Index3 ON smalldb(email) USING \\'org.apache.cassandra.index.sasi.SASIIndex\\' WITH OPTIONS = {\\'mode\\': \\'CONTAINS\\', \\'analyzer_class\\': \\'org.apache.cassandra.index.sasi.analyzer.NonTokenizingAnalyzer\\', \\'case_sensitive\\': \\'false\\'};')\n",
    "\n",
    "# define the CQL query\n",
    "test = 'SELECT materialid FROM smalldb WHERE discipline = \\'maths\\' AND materialtype = \\'lecture slides\\' AND email LIKE \\'%gmail.com\\' ALLOW FILTERING;'\n",
    "\n",
    "# run the query\n",
    "smallqueryTest_query3 = session.execute(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055420c",
   "metadata": {},
   "source": [
    "A <i>ReadFailure error</i> is thrown and I believe it is associated to the use of a custom index together with two regular indices. In fact, by executing two separate queries with the regular indices or the custom one, results are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3f23dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(materialid='21516')\n",
      "Row(materialid='4163')\n",
      "Row(materialid='21576')\n",
      "Row(materialid='21308')\n",
      "Row(materialid='4328')\n",
      "Row(materialid='21329')\n",
      "Row(materialid='21370')\n",
      "Row(materialid='21490')\n",
      "Row(materialid='21367')\n",
      "Row(materialid='21727')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/85lnwyqj61q7l7rp510bt7340000gn/T/ipykernel_2237/435765169.py:4: DeprecationWarning: ResultSet indexing support will be removed in 4.0. Consider using ResultSet.one() to get a single row.\n",
      "  print(queryTest1[i])\n"
     ]
    }
   ],
   "source": [
    "test1 = 'SELECT materialid FROM smalldb WHERE discipline = \\'maths\\' AND materialtype = \\'lecture slides\\' ALLOW FILTERING;'\n",
    "queryTest1 = session.execute(test1)\n",
    "for i in range(0, 10):\n",
    "    print(queryTest1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9288ec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/85lnwyqj61q7l7rp510bt7340000gn/T/ipykernel_2237/1889992488.py:4: DeprecationWarning: ResultSet indexing support will be removed in 4.0. Consider using ResultSet.one() to get a single row.\n",
      "  print(queryTest2[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(materialid='17036')\n",
      "Row(materialid='9497')\n",
      "Row(materialid='11515')\n",
      "Row(materialid='9388')\n",
      "Row(materialid='19901')\n",
      "Row(materialid='23612')\n",
      "Row(materialid='8111')\n",
      "Row(materialid='13673')\n",
      "Row(materialid='11260')\n",
      "Row(materialid='18429')\n"
     ]
    }
   ],
   "source": [
    "test2 = 'SELECT materialid FROM smalldb WHERE email LIKE \\'%gmail.com\\' ALLOW FILTERING;'\n",
    "queryTest2 = session.execute(test2)\n",
    "for i in range(0, 10):\n",
    "    print(queryTest2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc955728",
   "metadata": {},
   "source": [
    "I then resolved to run a more simplified query and manipulate the result via programming language to obtain the desired result. I get the rows where the discipline is <i>maths</i> and the learning material type is <i>lecture slides</i>, then I run a custom function on the query result. The function allows to obtain the domain of the email in the query result, this allows me to count only those matching the string '<i>gmail.com</i>'. In this case, all the query results are of interest, since we want to know how many learning materials have been accessed by students, irrespective of possible repetitions in accessed learning materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d344e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function taking an email string and returning a substring with the email domain\n",
    "def findDomain(email):\n",
    "    delimiter = '@'\n",
    "    emailList = email.split(delimiter)\n",
    "    return emailList[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0ccb8fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "small_cassandra3 = 'SELECT email FROM smalldb WHERE discipline = \\'maths\\' AND materialtype = \\'lecture slides\\' ALLOW FILTERING;'\n",
    "\n",
    "before = time.time()\n",
    "small_query3 = session.execute(small_cassandra3)\n",
    "counter = 0\n",
    "for row in small_query3:\n",
    "    if findDomain(row.email) == 'gmail.com':\n",
    "        counter += 1\n",
    "    else:\n",
    "        counter += 0\n",
    "after = time.time()\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "96514eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2\n",
    "msec_duration = (after - before) * 1000\n",
    "smallDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "32615f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3\n",
    "for i in range(0, 30):\n",
    "    before = time.time()\n",
    "    small_query3 = session.execute(small_cassandra3)\n",
    "    counter = 0\n",
    "    for row in small_query3:\n",
    "        if findDomain(row.email) == 'gmail.com':\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter += 0\n",
    "    after = time.time()\n",
    "    msec_duration = (after - before) * 1000\n",
    "    smallDict['query3'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c0e087e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [],\n",
       " 'query2': [],\n",
       " 'query3': [349.41912,\n",
       "  301.29671,\n",
       "  461.88903,\n",
       "  223.49715,\n",
       "  248.20733,\n",
       "  268.64219,\n",
       "  229.48599,\n",
       "  273.98896,\n",
       "  226.70722,\n",
       "  250.63014,\n",
       "  255.47624,\n",
       "  267.39931,\n",
       "  258.90899,\n",
       "  244.13705,\n",
       "  251.39594,\n",
       "  237.3991,\n",
       "  237.19001,\n",
       "  227.19789,\n",
       "  220.70694,\n",
       "  233.03795,\n",
       "  250.90599,\n",
       "  247.4668,\n",
       "  238.18326,\n",
       "  249.78209,\n",
       "  482.79309,\n",
       "  297.97983,\n",
       "  232.23805,\n",
       "  436.58423,\n",
       "  233.19674,\n",
       "  225.93164,\n",
       "  229.34413],\n",
       " 'query4': []}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecfbbc8",
   "metadata": {},
   "source": [
    "<h4>Query 4</h4>\n",
    "<i>Query 4</i> presents analogous problems to those of <i>Query 3</i> since multiple occurrences of Korean countries are present in the table (South Korea, North Korea, Républica de Corea, etc.). In this case, to achieve the desired task, instead of trying to using a custom index, I preferred to exploit the <code>IN</code> set operator, by using it on the complete list of occurrences of Korean countries. In this way, only students from a country present in the limited set of Korean countries can be selected (together with those enrolled to a course of the discipline '<i>psychology</i>'). Considering that birthdate is simply another string value and given that string manipulation or pattern searches would require using a custom index together with other selecting approaches, which would raise the already experienced problems, choosing students born before year 2000 seems a  hard task, which, given my configuration, would probably be better achieved via programming language. So I define a function to extract the year from the <i>dateofbirth</i> field and check if the year precedes year 2000. I use the function on the elements of the Python set to which I have already added the query results, which seems a more efficient approach than using the function on the query result and later adding surviving results in a Python set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "be661dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function taking a birthdate string in the format yyyy-mm-dd and returning a substring with the year\n",
    "def findYear(dateofbirth):\n",
    "    delimiter = '-'\n",
    "    dateList = dateofbirth.split(delimiter)\n",
    "    return int(dateList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "34e7e2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cathrine Lie South Korea\n",
      "Raghav Sura North Korea\n",
      "Lynda Reynolds Korea\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "resSet4 = set()\n",
    "session.execute('CREATE INDEX IF NOT EXISTS query4Index1 ON smalldb(discipline);')\n",
    "small_cassandra4 = 'SELECT firstname, lastname, country, dateofbirth FROM smalldb WHERE discipline = \\'psychology\\' AND country IN (\\'Korea\\', \\'República de Corea\\', \\'South Korea\\', \\'North Korea\\', \\'República Popular Democrática de Corea\\', \\'Sydkorea\\') ALLOW FILTERING;'\n",
    "\n",
    "before = time.time()\n",
    "small_query4 = session.execute(small_cassandra4)\n",
    "for row in small_query4:\n",
    "    if findYear(row.dateofbirth) < 2000:\n",
    "        resSet4.add(row)\n",
    "after = time.time()\n",
    "\n",
    "for element in resSet4:\n",
    "    print(element.firstname, element.lastname, element.country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "40d0ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2\n",
    "msec_duration = (after - before) * 1000\n",
    "smallDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0cf438c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3\n",
    "for i in range(0, 30):\n",
    "    before = time.time()\n",
    "    small_query4 = session.execute(small_cassandra4)\n",
    "    for row in small_query4:\n",
    "        resSet4.add(row)\n",
    "    after = time.time()\n",
    "    msec_duration = (after - before) * 1000\n",
    "    smallDict['query4'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a761eca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [],\n",
       " 'query2': [],\n",
       " 'query3': [349.41912,\n",
       "  301.29671,\n",
       "  461.88903,\n",
       "  223.49715,\n",
       "  248.20733,\n",
       "  268.64219,\n",
       "  229.48599,\n",
       "  273.98896,\n",
       "  226.70722,\n",
       "  250.63014,\n",
       "  255.47624,\n",
       "  267.39931,\n",
       "  258.90899,\n",
       "  244.13705,\n",
       "  251.39594,\n",
       "  237.3991,\n",
       "  237.19001,\n",
       "  227.19789,\n",
       "  220.70694,\n",
       "  233.03795,\n",
       "  250.90599,\n",
       "  247.4668,\n",
       "  238.18326,\n",
       "  249.78209,\n",
       "  482.79309,\n",
       "  297.97983,\n",
       "  232.23805,\n",
       "  436.58423,\n",
       "  233.19674,\n",
       "  225.93164,\n",
       "  229.34413],\n",
       " 'query4': [695.7531,\n",
       "  635.82397,\n",
       "  750.34499,\n",
       "  712.49294,\n",
       "  661.04388,\n",
       "  776.11971,\n",
       "  668.58721,\n",
       "  652.04597,\n",
       "  628.80802,\n",
       "  687.53362,\n",
       "  648.87118,\n",
       "  629.42886,\n",
       "  686.27191,\n",
       "  590.88993,\n",
       "  626.34301,\n",
       "  655.761,\n",
       "  616.15419,\n",
       "  822.73889,\n",
       "  710.8779,\n",
       "  670.41206,\n",
       "  1154.93011,\n",
       "  747.22934,\n",
       "  931.73409,\n",
       "  883.31389,\n",
       "  694.96393,\n",
       "  785.81524,\n",
       "  923.58875,\n",
       "  1341.88581,\n",
       "  600.34895,\n",
       "  739.90393,\n",
       "  705.01399]}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9189d",
   "metadata": {},
   "source": [
    "<h3>Table with 500k records</h3><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2899d420",
   "metadata": {},
   "source": [
    "<h4>Query1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d97bc780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nath Nicolas\n",
      "Narciso Ferrán\n",
      "Karl Christensen\n",
      "Débora Vaz\n",
      "Yuvaan Dara\n",
      "Ana Narušis\n",
      "Ingeborg Amundsen\n",
      "Ledün Soylu\n",
      "Casandra Arenas\n",
      "Joris Kavaliauskas\n",
      "Custodia Hidalgo\n",
      "Cathrine Lie\n",
      "Émile Nicolas\n",
      "Christl Henschel\n",
      "Arthur Laroche\n",
      "Patrícia Leite\n",
      "Vigilija Gaižauskas\n",
      "Sarah Lara\n",
      "Miguel Real\n",
      "Nedas Naujokas\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "resSet1 = set()\n",
    "session.execute('CREATE INDEX IF NOT EXISTS med_query1Index ON mediumdb(courseid);')\n",
    "medium_cassandra1 = 'SELECT firstName, lastName FROM mediumdb WHERE courseid = \\'192\\';'\n",
    "\n",
    "before = time.time()\n",
    "medium_query1 = session.execute(medium_cassandra1)\n",
    "for row in medium_query1:\n",
    "    resSet1.add(row)\n",
    "after = time.time()\n",
    "\n",
    "for element in resSet1:\n",
    "    print(element[0], element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00b0d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2\n",
    "msec_duration = (after - before) * 1000\n",
    "mediumDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efbae1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3\n",
    "for i in range(0, 30):\n",
    "    resSet1 = set()\n",
    "    before = time.time()\n",
    "    medium_query1 = session.execute(medium_cassandra1)\n",
    "    for row in medium_query1:\n",
    "        resSet1.add(row)\n",
    "    after = time.time()\n",
    "    msec_duration = (after - before) * 1000\n",
    "    mediumDict['query1'].append(round(msec_duration, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05d0d58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query1': [145.22409,\n",
       "  92.65804,\n",
       "  81.97904,\n",
       "  79.16284,\n",
       "  74.36013,\n",
       "  104.69818,\n",
       "  137.92205,\n",
       "  117.68174,\n",
       "  109.49111,\n",
       "  91.62211,\n",
       "  89.98489,\n",
       "  75.12617,\n",
       "  65.26208,\n",
       "  64.42904,\n",
       "  64.4331,\n",
       "  64.71801,\n",
       "  60.58002,\n",
       "  66.72716,\n",
       "  86.42983,\n",
       "  122.89691,\n",
       "  73.32587,\n",
       "  78.81594,\n",
       "  70.5359,\n",
       "  63.82418,\n",
       "  72.45398,\n",
       "  113.89518,\n",
       "  95.33811,\n",
       "  63.55691,\n",
       "  60.77981,\n",
       "  67.7979],\n",
       " 'query2': [],\n",
       " 'query3': [],\n",
       " 'query4': []}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediumDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ebad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
