{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b658c051",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h2>Online learning platform database - Redis</h2>\n",
    "    <h3>Methodologies applied for loading the data and performing the queries</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544d0b6",
   "metadata": {},
   "source": [
    "<h3>Preliminary operations: import csv files into Redis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf09d3",
   "metadata": {},
   "source": [
    "Given Redis' nature of a <i>key-value store</i> rather than a classical DBMS, importing is a task better performed via a programming language. This requires to load the csv file and store the data into a suitable data structure, then use the programming language to connect to a Redis instance and store the data into a Redis data type. Hence, this section on Redis will have a slightly different format from the previous ones, starting with describing how to manage csv files from Python and then introducing the Redis' Python driver and the mothods used to connect to a Redis instance from Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5e089",
   "metadata": {},
   "source": [
    "<h3>Importing csv files into Python</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b855d73",
   "metadata": {},
   "source": [
    "Importing a csv file into Python is best performed via the <code>csv</code> module, contained in the Python standard library. It contains methods for reading (<code>csv.reader</code>) or writing (<code>csv.writer</code>) csv files. By starting a connection to a file we can read it line by line and store the fields within each line into lists. The file lines can be stored into a dictionary of lists where each line number corresponds to the dictionary key and the associated list contains the fields included in the csv lines. The above described procedure is stored into a function that can be called for each of the four datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48da2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PURPOSE:  stores a csv file into a Python dictionary (dictionary keys are row numbers, values are rows as lists)\n",
    "# ARGUMENTS:  a path (string), a csv filename including extension (string), a dictionary name\n",
    "#   RETURNS:  a dictionary\n",
    "def importCSVfile(pathName, csvFileName):\n",
    "    import csv\n",
    "    key = 0\n",
    "    dictName = dict()\n",
    "    with open(pathName + csvFileName, newline = '') as csvFile:\n",
    "        reader = csv.reader(csvFile, delimiter = ',')\n",
    "        for line in reader:\n",
    "            dictName[key] = line\n",
    "            key += 1\n",
    "    return dictName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a75ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the importCSVfile function for the four differently sized datasets\n",
    "path = '/Users/mau/OneDrive - unime.it/Learning/CdL Informatica/Anno II - Database/Module B/project/tables/'\n",
    "\n",
    "# 250k rows dataset to dict\n",
    "smallDB = importCSVfile(path, 'dataset250k.csv')\n",
    "\n",
    "# 500k rows dataset to dict\n",
    "mediumDB = importCSVfile(path, 'dataset500k.csv')\n",
    "\n",
    "# 750k rows dataset to dict\n",
    "largeDB = importCSVfile(path, 'dataset750k.csv')\n",
    "\n",
    "# 1m rows dataset to dict\n",
    "humongousDB = importCSVfile(path, 'dataset1m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2097dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of the four dictionaries, from the smallest to the largest:\n",
      "\n",
      "smallDB: 250001 mediumDB: 500001 largeDB: 750001 humongousDB: 1000001\n"
     ]
    }
   ],
   "source": [
    "print('Lengths of the four dictionaries, from the smallest to the largest:\\n')\n",
    "print('smallDB:', len(smallDB), 'mediumDB:', len(mediumDB), 'largeDB:', len(largeDB), 'humongousDB:', len(humongousDB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe4135",
   "metadata": {},
   "source": [
    "<h3>Python - Redis interaction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad76a4",
   "metadata": {},
   "source": [
    "Interaction between a Python API and a Redis key-value store requires the installation of a specific driver. The usual list of drivers for various programming languages is provided in the <a href = 'https://redis.io/resources/clients/'>Clients</a> web page of the Redis website: <a href = 'https://redis-py.readthedocs.io/en/stable/index.html'>redis-py</a> is the driver developed by <i>Redis Inc.</i> for a Python programming environment.<br>After having installed the driver, it can be imported into a Python environment the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5469de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddef33",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Establishing a connection to a Redis database\n",
    "</h4><br>\n",
    "We can connect to a Redis instance by simply assigning a <code>Redis()</code> object to a Python variable. By default, the driver sets a connection to a local Redis instance on port 6379. Host name and port can also be specified as arguments. By default, Redis returns responses as bytes in Python. We can be returned responses decoded as strings by specifying the <code>decode_responses</code> argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629d30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRedis = redis.Redis(host = 'localhost', port = 6379, decode_responses = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d5288",
   "metadata": {},
   "source": [
    "I found it more convenient to access different Redis instances to perform the querying tests. This allows me to consider each instance as dedicated to a unique hash type (prefix). So each Redis instance could be conceptually treated as if it were an independent collection of documents. I could also store 2.5 million keys in a unique Redis instance and each hash prefix would allow identifying to which '<i>collection</i>' each document belonged. To allow for the chosen implementation, I create three more Redis instances: in the first one (<i>myRedis</i>) I will store the smallest dataset, in the second one (<i>myRedis2</i>) I will store the dataset with 500k records, in the third one (<i>myRedis3</i>) I will store the dataset with 750k records and in the fourth one (<i>myRedis4</i>) I will store the dataset with 1m records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67487d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRedis2 = redis.Redis(host = 'localhost', port = 6382, decode_responses = True)\n",
    "myRedis3 = redis.Redis(host = 'localhost', port = 6383, decode_responses = True)\n",
    "myRedis4 = redis.Redis(host = 'localhost', port = 6384, decode_responses = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccffa2dd",
   "metadata": {},
   "source": [
    "A Redis connection implements a <code>CoreCommands</code> class which contains functions that can replicate all the <a href = 'https://redis-py.readthedocs.io/en/stable/commands.html'>commands</a> provided within the <i>redis-cli</i> API. Since Python is case sensitive, however, they must be typed in the correct letter case (they usually use lowercase letters). The list of all available methods is accessible via the usual <code>dir(<i>redisObject</i>)</code> function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0ab66",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Store data into Redis hashes [ ! LONG PROCESSES FOLLOW ! ]\n",
    "</h4><br>\n",
    "<i>Hashes</i> are a Redis data type that allows the association of keys and values. A hash object has a name and a list of key-value stores. In our case, the keys may represent the field (column) names contained in the first row of the csv file (header) while the values are the field values contained in the other csv rows. We can create one hash per row by creating hash names of the form <i>small:rownumber</i>, where the text before the colon represents the dataset and the text after the colon is the row number. Thus, each row becomes a hash where the hash keys are common across all hashes in the dataset. This is helpful because hash keys may work as a schema for implementing queries. This procedure is stored into a function that takes a dictionary as argument, so that it is sufficient to feed it the desired dataset (one of the four differently sized dataset stored into the four dictionaries above) to have data sent to Redis (the process is quite long even for the 250k rows dataset, anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0688a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PURPOSE: stores Python dictionary key-value pairs to Redis hashes with a prefix\n",
    "# ARGUMENTS: a Redis instance, a dictionary(dict), a string we want to use as hash prefix\n",
    "#            (usually the hash string ends with a colon to separate prefix and row number)\n",
    "#   RETURNS: nothing\n",
    "def sendToRedis(redisInstance, datasetDict, hashPrefix):\n",
    "    for i in range(1, len(datasetDict)):\n",
    "        for j in range(0, len(datasetDict[0])):\n",
    "            redisInstance.hset(hashPrefix + str(i), datasetDict[0][j], datasetDict[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7b87a",
   "metadata": {},
   "source": [
    "If we desire to remove hashes prefixed with the dataset name, sent to Redis as above explained, we can also reverse the process by looping over the length of the dataset dictionary (the dictionary keys range from 0 to 250k or 500k, etc.), assigning the dataset name + colon + the row number to the hashes we want to remove and applying the <code>delete</code> method on them. This will remove them one by one (a long process as well as the one of loading them). Again, we store the procedure into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29087e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PURPOSE: removes Redis hashes sent with a prefix from a Python dictionary\n",
    "# ARGUMENTS: a Redis instance, a dictionary(dict), a string we want to use as hash prefix\n",
    "#            (usually the hash string ends with a colon to separate prefix and row number)\n",
    "#   RETURNS: nothing\n",
    "def removeFromRedis(redisInstance, datasetDict, hashPrefix):\n",
    "    for i in range(1, len(datasetDict)):\n",
    "        redisInstance.delete(hashPrefix + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE LINES START LONG PROCESSES, SO I COMMENT THEM OUT TO AVOID UNCAUTIOUS USE\n",
    "'''\n",
    "# 250k keys dict to Redis hashes\n",
    "sendToRedis(myRedis, smallDB, 'smallDB:')\n",
    "\n",
    "# 500k keys dict to Redis hashes\n",
    "sendToRedis(myRedis2, mediumDB, 'mediumDB:')\n",
    "\n",
    "# 750k keys dict to Redis hashes\n",
    "sendToRedis(myRedis3, largeDB, 'largeDB:')\n",
    "\n",
    "# 1m keys dict to Redis hashes\n",
    "sendToRedis(myRedis4, humongousDB, 'humongousDB:')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59ecabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional delete hashes process\n",
    "# removeFromRedis(myRedis, mediumDB, 'mediumDB:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295e871",
   "metadata": {},
   "source": [
    "We can consider each hash as a single document in a collection of documents where keys are common across them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f459600",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Executing a query (<i>RediSearch</i>)\n",
    "</h4><br>\n",
    "Queries can be performed by using the <a href = 'https://docs.redis.com/latest/stack/search/'>RediSearch module</a>, which builds indices based on the provided schema.\n",
    "\n",
    "- Creating an index <code>FT.CREATE</code><br>\n",
    "  This is a very important step to take before performing a query. Creating an index allows to define the <code>SCHEMA</code> of the data for the purpose of performing a query. Creating the index is strongly query-oriented. The schema is in fact a list of secondary indices that we base our queries on.<br>\n",
    "<code>\n",
    "    FT.CREATE <i>indexName</i> ON hash PREFIX 1 <i>prefixPattern</i> SCHEMA [<i>fieldName</i> [TYPE] [OPTIONS] ... ]\n",
    "</code>\n",
    "<br>\n",
    "  As the example syntax above shows, we specify:\n",
    "  \n",
    "  - the name of the index we are creating (<i>indexName</i>);\n",
    "  - the data type on which we are creating it (HASH or JSON supported);\n",
    "  - the data prefix (we have a pattern that allows us to put together many data types as a collection);\n",
    "  - the schema, i.e. the fields (hash keys, to be more precise) we want to use as indices followed by the value type (TEXT, NUMERIC, TAG, ...) and its options (SORTABLE, ...).<br><br>\n",
    "\n",
    "- Performing a query <code>FT.SEARCH</code><br>\n",
    "  After having created an index we can use the secondary indices in the schema to select elements based on specific values. \n",
    "<br>\n",
    "<code>\n",
    "    FT.SEARCH <i>indexName</i> '@fieldName:fieldValue' RETURN [nr of projected fields] [<i>fieldNames</i>]\n",
    "</code>\n",
    "<br>\n",
    "  As the example syntax shows, we specify:\n",
    "  \n",
    "  - the name of the index we want to use (<i>indexName</i>);\n",
    "  - the selection criteria (<i>fieldName</i> introduced by a <i><b>at sign (@)</b></i> and <i>fieldValue</i> introduced by a <i><b>colon sign (:)</b></i>);\n",
    "  - the projected fields (introduced by the <code>RETURN</code> keyword and their number)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b61e0",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Executing a query in redis-py\n",
    "</h4><br>\n",
    "Within a Redis connection object, the <code>ft</code> method creates a new object providing methods that replicate the <a href = 'https://redis-py.readthedocs.io/en/stable/redismodules.html#redisearch-commands'>RediSearch commands</a> that we have introduced in the previous paragraph. Like Redis commands for creating data types, they also are only lowercase. We can create as many <i>RediSearch</i> objects as the indices we want to use to perform queries.<br> It is also advisable to import needed dependencies prior to index creation. <code>TextField</code>, <code>NumericField</code>, <code>TagField</code>, specify the value type of the fields included in the schema. The <code>IndexDefinition</code> dependency is needed to specify the common prefix of the Redis data types that must be indexed. The other imported dependency, <code>Query</code>, is useful for the execution of complex queries, allowing to specify parameters that can be chained to one another. Applying a parameter to a <code>Query()</code> object returns a query object. Applying a chained parameter results in applaying it to the query object returned by the preceding attached parameter and so on. The <code>aggregation</code> dependency is needed to perform aggregate queries by passing an <i>aggregation request</i> to the <code>aggregate</code> method of the index object. Finally, the <code>reducers</code> dependency stores methods to reduce aggregation results into a single record by applying appropriate functions such as <i>count</i>, <i>sum</i>, <i>min</i>, <i>max</i>, <i>average</i> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbb2c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from redis.commands.search.field import TextField, NumericField, TagField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.query import Query\n",
    "import redis.commands.search.aggregation as aggregations\n",
    "import redis.commands.search.reducers as reducers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9017bf6",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Create an index\n",
    "</h4><br>\n",
    "An index can be created with the <code>create_index</code> method of any <i>RediSearch</i> object. We can optionally pass the index name as an argument (otherwise a default '<i>idx</i>' name will be used) and assign the <i>RediSearch</i> object to a Python variable. Then we can pass the schema (each field name of the schema must be enclosed within the function that specifies its value type (<code>TextField</code>, <code>NumericField</code>, <code>TagField</code>) and index definition to the index object. The <code>info()</code> method of the index object is useful to retrieve index information.<br>Notice that if we need to redefine a previously created index, we must first drop it with the <code>dropindex</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b70cca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RediSearch object\n",
    "exampleRS = myRedis.ft('idx:exampleIdx')\n",
    "\n",
    "# (if it exists drop and) create index object\n",
    "#exampleRS.dropindex()\n",
    "schema = (TextField('studentID'), TextField('courseID'), TextField('materialID'))\n",
    "index_definition = IndexDefinition(prefix = 'smallDataset:')\n",
    "exampleRS.create_index(schema, index_definition)\n",
    "#redisIdx.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d496ff",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Run the related query\n",
    "</h4><br>\n",
    "A query depends on the previously created index and is performed via the <code>search</code> method of the index object. It is sufficient to pass a query string to the <code>search</code> method, where a query string is simply a string value that can be found in either of the secondary indices in the schema or a string of the form '<i>@fieldName:fieldValue</i>' if we seek to find the value in a specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a0e0df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result{508 total, docs: [Document {'id': 'smallDataset:180027', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '1439', 'firstName': 'Danilo', 'lastName': 'Barbosa', 'dateOfBirth': '1975-9-5', 'genre': 'male', 'country': 'Granada', 'town': 'Santos do Norte', 'email': 'danilo.barbosa@hotmail.com', 'materialID': '32031', 'unit': 'Unit 4', 'materialType': 'lecture slides', 'name': '[SLIDES] Cellular Respiration, Part 1 ', 'dimension': '9', 'accessDate': '2023-05-19'}, Document {'id': 'smallDataset:102996', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '834', 'firstName': 'Geir', 'lastName': 'Brekke', 'dateOfBirth': '1993-10-22', 'genre': 'male', 'country': 'Republic of the Congo', 'town': 'Trondberg', 'email': 'geir.brekke@yahoo.com', 'materialID': '31985', 'unit': 'Unit 1', 'materialType': 'video lecture', 'name': '[VIDEO] Assessing Breath Sounds Demonstration', 'dimension': '5', 'accessDate': '2023-01-03'}, Document {'id': 'smallDataset:90386', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '735', 'firstName': 'Jeffrey', 'lastName': 'Wheeler', 'dateOfBirth': '1988-3-26', 'genre': 'male', 'country': 'Djibouti', 'town': 'Port Barbara', 'email': 'jeffrey.wheeler@yahoo.com', 'materialID': '32029', 'unit': 'Unit 4', 'materialType': 'lecture slides', 'name': '[SLIDES] Video Prototyping', 'dimension': '9', 'accessDate': '2023-08-21'}, Document {'id': 'smallDataset:90405', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '735', 'firstName': 'Jeffrey', 'lastName': 'Wheeler', 'dateOfBirth': '1988-3-26', 'genre': 'male', 'country': 'Djibouti', 'town': 'Port Barbara', 'email': 'jeffrey.wheeler@yahoo.com', 'materialID': '32053', 'unit': 'Unit 6', 'materialType': 'lecture slides', 'name': '[SLIDES] Negative Externalities', 'dimension': '9', 'accessDate': '2023-07-04'}, Document {'id': 'smallDataset:86714', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '709', 'firstName': 'Jordan', 'lastName': 'Cole', 'dateOfBirth': '1994-9-24', 'genre': 'male', 'country': 'Saint Vincent and the Grenadines', 'town': 'South Maxville', 'email': 'jordan.cole@outlook.com', 'materialID': '32024', 'unit': 'Unit 4', 'materialType': 'video lecture', 'name': '[VIDEO] Maintaining Body Temperature ', 'dimension': '4', 'accessDate': '2022-08-11'}, Document {'id': 'smallDataset:249258', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '1999', 'firstName': 'Sebastião', 'lastName': 'Sousa', 'dateOfBirth': '1988-11-15', 'genre': 'male', 'country': 'Gibraltar', 'town': 'Castelo Branco', 'email': 'sebastião.sousa@clix.pt', 'materialID': '31998', 'unit': 'Unit 2', 'materialType': 'video lecture', 'name': '[VIDEO] Blood Circulation ', 'dimension': '10', 'accessDate': '2022-09-08'}, Document {'id': 'smallDataset:180014', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '1439', 'firstName': 'Danilo', 'lastName': 'Barbosa', 'dateOfBirth': '1975-9-5', 'genre': 'male', 'country': 'Granada', 'town': 'Santos do Norte', 'email': 'danilo.barbosa@hotmail.com', 'materialID': '32016', 'unit': 'Unit 4', 'materialType': 'video lecture', 'name': '[VIDEO] How to Switch Sessions of the Course', 'dimension': '2', 'accessDate': '2023-06-30'}, Document {'id': 'smallDataset:176846', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '1410', 'firstName': 'Candelaria', 'lastName': 'Alba', 'dateOfBirth': '1967-12-19', 'genre': 'non binary', 'country': 'Bangladesh', 'town': 'Badajoz', 'email': 'candelaria.alba@hotmail.com', 'materialID': '31982', 'unit': 'Unit 1', 'materialType': 'lecture slides', 'name': '[SLIDES] Evaluation', 'dimension': '4', 'accessDate': '2023-05-31'}, Document {'id': 'smallDataset:86688', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '709', 'firstName': 'Jordan', 'lastName': 'Cole', 'dateOfBirth': '1994-9-24', 'genre': 'male', 'country': 'Saint Vincent and the Grenadines', 'town': 'South Maxville', 'email': 'jordan.cole@outlook.com', 'materialID': '31994', 'unit': 'Unit 1', 'materialType': 'lecture slides', 'name': '[SLIDES] ', 'dimension': '11', 'accessDate': '2022-03-19'}, Document {'id': 'smallDataset:90395', 'payload': None, 'courseID': '450', 'discipline': 'miscellaneous', 'courseName': 'Game Theory', 'courseYear': '2023', 'syllabus': 'http://learning_platform.com/gametheory/syllabus', 'studentID': '735', 'firstName': 'Jeffrey', 'lastName': 'Wheeler', 'dateOfBirth': '1988-3-26', 'genre': 'male', 'country': 'Djibouti', 'town': 'Port Barbara', 'email': 'jeffrey.wheeler@yahoo.com', 'materialID': '32041', 'unit': 'Unit 5', 'materialType': 'video lecture', 'name': '[VIDEO] A Problem for Arguments', 'dimension': '2', 'accessDate': '2023-07-24'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleRS.search('450')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b72819",
   "metadata": {},
   "source": [
    "A query object stores the integer showing the <b>total number of found documents into the <code>total</code> attribute</b>, the <b>query execution time (in milliseconds) into the <code>duration</code> attribute</b> and all <b>the docs (hashes) matching the selection criteria into the <code>docs</code> attribute.</b> Assigning a query result to a Python variable allows us to retrieve these information at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb88102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query execution time was: 7.215023 milliseconds, and the number of documents matching it is: 508\n",
      "\n",
      "A sample of the courseID and student name for the query results is the following:\n",
      "\n",
      "1 450 Danilo Barbosa\n",
      "2 450 Geir Brekke\n",
      "3 450 Jeffrey Wheeler\n",
      "4 450 Jeffrey Wheeler\n",
      "5 450 Jordan Cole\n",
      "6 450 Sebastião Sousa\n",
      "7 450 Danilo Barbosa\n",
      "8 450 Candelaria Alba\n",
      "9 450 Jordan Cole\n",
      "10 450 Jeffrey Wheeler\n"
     ]
    }
   ],
   "source": [
    "exampleQuery = exampleRS.search('450')\n",
    "print('The query execution time was: %f milliseconds, and the number of documents matching it is: %i\\n' % (exampleQuery.duration, exampleQuery.total))\n",
    "print('A sample of the courseID and student name for the query results is the following:\\n')\n",
    "counter = 0\n",
    "for doc in exampleQuery.docs:\n",
    "    counter += 1\n",
    "    print(counter, doc['courseID'], doc['firstName'], doc['lastName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3e7a7",
   "metadata": {},
   "source": [
    "The above example shows that the value '<i>450</i>' is searched throughout all the secondary indices in the schema of the <i>exampleRS</i> index, so we may  have student IDs, course IDs and material IDs matching the requested value. In the printed results, however, the only field that can match the searched value is the course ID. In the other cases, it may be the student ID or the material ID that we have found matching the searched value, but we cannot tell because the only projected secondary index field is the course ID. The above result also shows a limitation in the query results displayed by Redis. This is controlled by the optional argument <code>LIMIT</code>, which sets the offset and the number of results displayed. The default is 0 10, which returns 10 items starting from the first (0) result. The redis-cli syntax is simply:<br>\n",
    "<code>\n",
    "    FT.SEARCH '<i>@fieldName:fieldValue</i>' LIMIT [first num] RETURN [nr of projected fields] [<i>fieldNames</i>]\n",
    "</code><br>\n",
    "To control this parameter in our Python environment we must implement the query differently. It is not sufficient to pass a string to the <code>search</code> method, but we need to use a <code>Query</code> object as illustrated below. A <code>Query</code> object is used for complex queries allowing to specify parameters on the object itself. Query object parameters can be chained to adapt the query results to our needs. One of the parameters is <code>paging(<i>first</i>, <i>num</i>)</code> which replicates the effects of the <code>LIMIT</code> argument in redis-cli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa014897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 450 Danilo Barbosa\n",
      "2 450 Geir Brekke\n",
      "3 450 Jeffrey Wheeler\n",
      "4 450 Jeffrey Wheeler\n",
      "5 450 Jordan Cole\n",
      "6 450 Sebastião Sousa\n",
      "7 450 Danilo Barbosa\n",
      "8 450 Candelaria Alba\n",
      "9 450 Jordan Cole\n",
      "10 450 Jeffrey Wheeler\n",
      "11 313 Walentina Bohnbach\n",
      "12 313 Walentina Bohnbach\n",
      "13 450 Candelaria Alba\n",
      "14 450 Sebastião Sousa\n",
      "15 450 Sebastião Sousa\n"
     ]
    }
   ],
   "source": [
    "exampleQuery2 = exampleRS.search(Query('450').paging(0, 15))\n",
    "counter2 = 0\n",
    "for doc in exampleQuery2.docs:\n",
    "    counter2 += 1\n",
    "    print(counter2, doc['courseID'], doc['firstName'], doc['lastName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe787d",
   "metadata": {},
   "source": [
    "Instead of retrieving the entire documents, if we are perfectly aware of the information we need from a query, we can project the required fields and save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33553633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of the courseID and student name for the query results is the following:\n",
      "\n",
      "1 313 Walentina Bohnbach\n",
      "2 313 Walentina Bohnbach\n",
      "3 313 Walentina Bohnbach\n",
      "4 313 Walentina Bohnbach\n",
      "5 161 Walentina Bohnbach\n",
      "6 161 Walentina Bohnbach\n",
      "7 313 Walentina Bohnbach\n",
      "8 161 Walentina Bohnbach\n",
      "9 313 Walentina Bohnbach\n",
      "10 313 Walentina Bohnbach\n",
      "11 161 Walentina Bohnbach\n",
      "12 161 Walentina Bohnbach\n",
      "13 313 Walentina Bohnbach\n",
      "14 313 Walentina Bohnbach\n",
      "15 313 Walentina Bohnbach\n"
     ]
    }
   ],
   "source": [
    "exampleQuery3 = exampleRS.search(Query('@studentID:450').return_fields('firstName', 'lastName', 'courseID').paging(0, 15))\n",
    "print('A sample of the courseID and student name for the query results is the following:\\n')\n",
    "counter3 = 0\n",
    "for doc in exampleQuery3.docs:\n",
    "    counter3 += 1\n",
    "    print(counter3, doc['courseID'], doc['firstName'], doc['lastName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b758a62",
   "metadata": {},
   "source": [
    "To avoid replicated results we must use a different type of query, an aggregate query. We use the <code>aggregation</code> dependency to build an aggregation request and the <code>aggregate</code> method to which we pass the aggregation request. Also, we need to set a new index because the schema must support the fields we want to use to perform aggregation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ecad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exampleRS2.dropindex()\n",
    "\n",
    "# new RediSearch object\n",
    "exampleRS2 = myRedis.ft('idx:exampleIdx2')\n",
    "\n",
    "# new index (with new schema)\n",
    "schema2 = (TextField('studentID'), TextField('firstName'), TextField('lastName'))\n",
    "exampleRS2.create_index(schema2, index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599156c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walentina Bohnbach\n"
     ]
    }
   ],
   "source": [
    "# aggregate request and query\n",
    "aggRequest = aggregations.AggregateRequest('@studentID:450').group_by({'@firstName', '@lastName'})\n",
    "exampleQuery4 = exampleRS2.aggregate(aggRequest)\n",
    "for res in exampleQuery4.rows:\n",
    "    print(res[3], res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57940b07",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Measuring and displaying the query execution time\n",
    "</h4>\n",
    "<h4>\n",
    "- method 1: <code>time()</code>\n",
    "</h4><br>\n",
    "To display the query execution time we can use the Python <a href = 'https://docs.python.org/3/library/time.html'><i>time</i></a> module and its <code>time()</code> function. The function returns the system time at a floating point precision, so the query execution time can be measured as a large number of fractions of a second. It is sufficient to assign the time before the query execution to a variable and the time after the query execution to another variable. The difference between the two variables will measure the query execution time. Obviously, the time for the Python API to connect to the Redis server and the time to return to the Python API after the query execution will be summed up to the query execution time at the DBMS level. The unit measure here is seconds, so we get the time execution in milliseconds by multiplying the difference by 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# performing exampleQuery3 again:\n",
    "startEx3 = time()\n",
    "exampleRS.search(Query('@studentID:450').return_fields('firstName', 'lastName', 'courseID').paging(0, 15))\n",
    "endEx3 = time()\n",
    "timeEx3 = (endEx3 - startEx3) * 1000\n",
    "\n",
    "# performing exampleQuery4 again:\n",
    "startEx4 = time()\n",
    "exampleRS2.aggregate(aggRequest)\n",
    "endEx4 = time()\n",
    "timeEx4 = (endEx4 - startEx4) * 1000\n",
    "\n",
    "print('The query execution time for exampleQuery3 was: %f milliseconds.' % timeEx3)\n",
    "print('The query execution time for exampleQuery4 was: %f milliseconds.' % timeEx4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b624969",
   "metadata": {},
   "source": [
    "<h4>\n",
    "- method 2: <code>duration</code>\n",
    "</h4><br>\n",
    "To display the query execution time we can also use the <code>duration</code> method of a query object. However, as the following execution shows, this method is not available for aggregation objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf689977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query execution time was: 6.802797 milliseconds.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AggregateResult' object has no attribute 'duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe query execution time was: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m milliseconds.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m exampleQuery3\u001b[38;5;241m.\u001b[39mduration)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe query execution time was: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m milliseconds.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[43mexampleQuery4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AggregateResult' object has no attribute 'duration'"
     ]
    }
   ],
   "source": [
    "print('The query execution time was: %f milliseconds.' % exampleQuery3.duration)\n",
    "print('The query execution time was: %f milliseconds.' % exampleQuery4.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e21de",
   "metadata": {},
   "source": [
    "<h4>\n",
    "- chosen method: <code>time()</code>\n",
    "</h4><br>\n",
    "For the above examined problem and for project consistency reasons, it is better to rely on the <code>time()</code> function of the Python <code>time</code> module to mark the time before and after operations are executed and compute their difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6037ff5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
